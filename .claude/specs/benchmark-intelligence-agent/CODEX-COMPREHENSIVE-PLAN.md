# Codex ç»¼åˆå¼€å‘æ–¹æ¡ˆï¼šBenchScope Phase 3-5 å®Œæ•´å®æ–½æŒ‡ä»¤

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-11-13
**æ‰§è¡Œè€…**: Codex
**ç›‘ç£è€…**: Claude Code
**å‰ç½®æ¡ä»¶**: Phase 1-2 MVPå·²å®Œæˆå¹¶éªŒæ”¶é€šè¿‡

---

## ğŸ“‹ æ–‡æ¡£ç›®å½•

1. [é¡¹ç›®ç°çŠ¶æ€»ç»“](#é¡¹ç›®ç°çŠ¶æ€»ç»“)
2. [Phase 3: æ ¸å¿ƒä¼˜åŒ– (2-3å¤©)](#phase-3-æ ¸å¿ƒä¼˜åŒ–)
3. [Phase 4: ç‰ˆæœ¬è·Ÿè¸ª (3-4å¤©)](#phase-4-ç‰ˆæœ¬è·Ÿè¸ª)
4. [Phase 5: å¢å¼ºåŠŸèƒ½ (2-3å¤©)](#phase-5-å¢å¼ºåŠŸèƒ½)
5. [æµ‹è¯•ä¸éªŒæ”¶æµç¨‹](#æµ‹è¯•ä¸éªŒæ”¶æµç¨‹)
6. [ä»£ç è§„èŒƒä¸çº¦æŸ](#ä»£ç è§„èŒƒä¸çº¦æŸ)

---

## é¡¹ç›®ç°çŠ¶æ€»ç»“

### âœ… Phase 1-2 å·²å®ŒæˆåŠŸèƒ½

| æ¨¡å— | çŠ¶æ€ | å…³é”®æŒ‡æ ‡ |
|------|------|---------|
| **æ•°æ®é‡‡é›†** | âœ… å®Œæˆ | arXiv(7å¤©) + GitHub(30å¤©) + HuggingFace(14å¤©) |
| **URLå»é‡** | âœ… å®Œæˆ | æŸ¥è¯¢é£ä¹¦Bitableï¼Œè¿‡æ»¤å·²æ¨é€å€™é€‰ |
| **è§„åˆ™é¢„ç­›é€‰** | âœ… å®Œæˆ | è¿‡æ»¤ç‡ç›®æ ‡70-90%ï¼ˆå½“å‰GitHub 100%è¿‡æ»¤ï¼‰ |
| **LLMè¯„åˆ†** | âœ… å®Œæˆ | GPT-4oè¯„åˆ†ï¼Œå¹³å‡åˆ†6.81/10ï¼Œæœˆæˆæœ¬<$1 |
| **é£ä¹¦å­˜å‚¨** | âœ… å®Œæˆ | ä¸»å­˜å‚¨(Bitable) + SQLiteé™çº§å¤‡ä»½ |
| **é£ä¹¦é€šçŸ¥** | âœ… å®Œæˆ | Webhookæ¨é€ï¼Œå®Œæ•´reasoningæ˜¾ç¤º |
| **ä¸»æµç¨‹ç¼–æ’** | âœ… å®Œæˆ | `src/main.py` 5æ­¥æµç¨‹è‡ªåŠ¨åŒ– |
| **å®ç”¨å·¥å…·** | âœ… å®Œæˆ | å»é‡è„šæœ¬ + æ¸…ç©ºè¡¨æ ¼è„šæœ¬ |

### ğŸ”„ å·²çŸ¥é—®é¢˜ä¸å¾…ä¼˜åŒ–ç‚¹

1. **GitHubå€™é€‰100%è¢«è¿‡æ»¤**: starsé˜ˆå€¼50è¿‡é«˜ï¼Œéœ€é™ä½åˆ°10å¹¶å¢åŠ å¤šç»´åº¦æ£€æŸ¥
2. **æ—¶é—´è¿‡æ»¤æœªå¯ç”¨**: é‡‡é›†å™¨æœªä½¿ç”¨å·²å®šä¹‰çš„æ—¶é—´çª—å£å¸¸é‡
3. **PwC APIå¤±æ•ˆ**: 301æ°¸ä¹…é‡å®šå‘åˆ°HuggingFaceï¼Œéœ€ç§»é™¤
4. **ç¼ºå°‘è¿ç»´å·¥å…·**: æ— æ—¥å¿—åˆ†æå·¥å…·ï¼Œæ’æŸ¥é—®é¢˜ä¸ä¾¿
5. **è¯„åˆ†æƒé‡å¾…ä¼˜åŒ–**: MGXé€‚é…åº¦æƒé‡è¿‡ä½ï¼ˆ10% â†’ 20%ï¼‰
6. **ç¼ºå°‘ç‰ˆæœ¬è·Ÿè¸ª**: æ— æ³•ç›‘æ§Benchmarkæ›´æ–°å’ŒSOTAå˜åŒ–
7. **é€šçŸ¥å•ä¸€**: ä»…æ–‡æœ¬é€šçŸ¥ï¼Œæ— å¡ç‰‡æ¶ˆæ¯å’Œäº¤äº’æŒ‰é’®

---

## Phase 3: æ ¸å¿ƒä¼˜åŒ–

**ç›®æ ‡**: è§£å†³Phase 1-2é—ç•™é—®é¢˜ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§å’Œè´¨é‡
**é¢„è®¡è€—æ—¶**: 2-3å¤©
**ä¼˜å…ˆçº§**: ğŸ”´ é«˜ï¼ˆå½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰

---

### Task 3.1: ç§»é™¤Papers with Codeé‡‡é›†å™¨

**ä¼˜å…ˆçº§**: ğŸ”´ P0ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç«‹å³æ‰§è¡Œï¼‰
**é¢„è®¡è€—æ—¶**: 30åˆ†é’Ÿ
**éš¾åº¦**: â­ (ç®€å•)

#### é—®é¢˜è¯Šæ–­

Papers with Code APIå·²æ°¸ä¹…301é‡å®šå‘åˆ°HuggingFace:
```
https://paperswithcode.com/api/v1/tasks/ â†’ https://huggingface.co/papers/trending
```

å½“å‰çŠ¶æ€ï¼š
- `src/collectors/pwc_collector.py` å­˜åœ¨ä½†æ— æ³•ä½¿ç”¨
- `src/main.py` ä¸­ä»ç„¶å°è¯•å®ä¾‹åŒ–PwCé‡‡é›†å™¨
- `src/common/constants.py` ä¸­æœ‰å¤§é‡PwCé…ç½®å¸¸é‡

#### ä»£ç ä¿®æ”¹æ¸…å•

**Step 1**: åˆ é™¤é‡‡é›†å™¨æ–‡ä»¶
```bash
rm src/collectors/pwc_collector.py
```

**Step 2**: æ›´æ–° `src/collectors/__init__.py`

æ‰¾åˆ°ï¼š
```python
from src.collectors.arxiv_collector import ArxivCollector
from src.collectors.github_collector import GitHubCollector
from src.collectors.huggingface_collector import HuggingFaceCollector
from src.collectors.pwc_collector import PwCCollector

__all__ = [
    "ArxivCollector",
    "GitHubCollector",
    "HuggingFaceCollector",
    "PwCCollector",
]
```

æ”¹ä¸ºï¼š
```python
from src.collectors.arxiv_collector import ArxivCollector
from src.collectors.github_collector import GitHubCollector
from src.collectors.huggingface_collector import HuggingFaceCollector

__all__ = [
    "ArxivCollector",
    "GitHubCollector",
    "HuggingFaceCollector",
]
```

**Step 3**: æ›´æ–° `src/main.py`

æ‰¾åˆ°ï¼š
```python
from src.collectors import ArxivCollector, GitHubCollector, HuggingFaceCollector, PwCCollector

collectors = [
    ArxivCollector(),
    GitHubCollector(),
    PwCCollector(),
    HuggingFaceCollector(settings=settings),
]
```

æ”¹ä¸ºï¼š
```python
from src.collectors import ArxivCollector, GitHubCollector, HuggingFaceCollector

collectors = [
    ArxivCollector(),
    GitHubCollector(),
    HuggingFaceCollector(settings=settings),
]
```

**Step 4**: æ¸…ç† `src/common/constants.py`

åˆ é™¤æ‰€æœ‰PwCç›¸å…³å¸¸é‡ï¼ˆé€šå¸¸åœ¨æ–‡ä»¶ä¸­æœç´¢"PWC_"ï¼‰ï¼š
```python
# åˆ é™¤ä»¥ä¸‹æ‰€æœ‰è¡Œ:
PWC_API_BASE: Final[str] = "https://paperswithcode.com/api/v1"
PWC_TIMEOUT_SECONDS: Final[int] = 15
PWC_QUERY_KEYWORDS: Final[list[str]] = ["coding", "agent", "reasoning"]
PWC_MIN_TASK_PAPERS: Final[int] = 3
PWC_PAGE_SIZE: Final[int] = 20
```

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. è¿è¡Œpipelineï¼Œä¸åº”çœ‹åˆ°PwCç›¸å…³é”™è¯¯
python src/main.py 2>&1 | grep -i "pwc"

# é¢„æœŸè¾“å‡º: æ— è¾“å‡ºï¼ˆæˆ–åªæœ‰é‡‡é›†å®Œæˆçš„æ—¥å¿—ï¼Œä½†æ— PwCé”™è¯¯ï¼‰

# 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²åˆ é™¤
ls src/collectors/pwc_collector.py

# é¢„æœŸè¾“å‡º: ls: cannot access 'src/collectors/pwc_collector.py': No such file or directory

# 3. æ£€æŸ¥å¯¼å…¥æ˜¯å¦æˆåŠŸ
python -c "from src.collectors import ArxivCollector, GitHubCollector, HuggingFaceCollector"

# é¢„æœŸè¾“å‡º: æ— æŠ¥é”™
```

#### Commitæ ¼å¼

```bash
git add src/collectors/__init__.py src/main.py src/common/constants.py
git commit -m "feat(collectors): ç§»é™¤Papers with Codeé‡‡é›†å™¨

- PwC APIå·²æ°¸ä¹…301é‡å®šå‘åˆ°HuggingFace
- åˆ é™¤pwc_collector.pyåŠç›¸å…³é…ç½®å¸¸é‡
- æ›´æ–°collectors/__init__.pyå’Œmain.pyå¯¼å…¥
- æ•°æ®æºç®€åŒ–ä¸ºarXiv + GitHub + HuggingFace"
```

---

### Task 3.2: ä¼˜åŒ–GitHubé¢„ç­›é€‰è§„åˆ™

**ä¼˜å…ˆçº§**: ğŸ”´ P0ï¼ˆè§£å†³100%è¿‡æ»¤é—®é¢˜ï¼‰
**é¢„è®¡è€—æ—¶**: 1-2å°æ—¶
**éš¾åº¦**: â­â­ (ä¸­ç­‰)

#### é—®é¢˜è¯Šæ–­

**å½“å‰é—®é¢˜**:
```python
# src/common/constants.py
PREFILTER_MIN_GITHUB_STARS: Final[int] = 50  # è¿‡é«˜ï¼Œå¯¼è‡´100%è¿‡æ»¤

# å®é™…æƒ…å†µ:
# - GitHubé‡‡é›†å™¨å·²æŒ‰starsæ’åºï¼Œåªå–Top 5
# - å†ç”¨50 starsè¿‡æ»¤å¯¼è‡´å¤§é‡æœ‰ä»·å€¼repoè¢«è¿‡æ»¤
# - æµ‹è¯•æ˜¾ç¤ºï¼š16ä¸ªé‡‡é›†å€™é€‰ â†’ 0ä¸ªé€šè¿‡é¢„ç­›é€‰ï¼ˆ100%è¿‡æ»¤ç‡ï¼‰
```

**æ ¹æœ¬åŸå› **:
1. GitHubé‡‡é›†å™¨è¿”å›çš„æ˜¯Top 5çƒ­é—¨repoï¼Œstarsé€šå¸¸>100
2. ä½†æ˜¯æ–°å…´Benchmarkå¯èƒ½starsè¾ƒå°‘ï¼ˆ10-50èŒƒå›´ï¼‰
3. å•ä¸€starsæŒ‡æ ‡ä¸è¶³ä»¥åˆ¤æ–­è´¨é‡

**è§£å†³æ–¹æ¡ˆ**:
1. é™ä½starsé˜ˆå€¼: `50 â†’ 10`
2. å¢åŠ READMEé•¿åº¦æ£€æŸ¥: `>500å­—ç¬¦`ï¼ˆé¿å…ç©ºrepoï¼‰
3. å¢åŠ æœ€è¿‘æ›´æ–°æ£€æŸ¥: `90å¤©å†…æœ‰commit`ï¼ˆé¿å…åºŸå¼ƒrepoï¼‰

#### ä»£ç ä¿®æ”¹æ¸…å•

**Step 1**: ä¿®æ”¹ `src/common/constants.py`

æ‰¾åˆ°é¢„ç­›é€‰é…ç½®éƒ¨åˆ†ï¼ˆé€šå¸¸åœ¨"# ---- Prefilter é…ç½® ----"æ³¨é‡Šä¸‹ï¼‰ï¼š
```python
# ---- Prefilter é…ç½® ----
PREFILTER_MIN_GITHUB_STARS: Final[int] = 50
```

ä¿®æ”¹ä¸ºï¼š
```python
# ---- Prefilter é…ç½® ----
PREFILTER_MIN_GITHUB_STARS: Final[int] = 10  # é™ä½åˆ°10 starsï¼ˆæ–°å…´Benchmarkå¯èƒ½starsè¾ƒå°‘ï¼‰
PREFILTER_MIN_README_LENGTH: Final[int] = 500  # READMEæœ€å°‘500å­—ç¬¦ï¼ˆé¿å…ç©ºrepoï¼‰
PREFILTER_RECENT_DAYS: Final[int] = 90  # 90å¤©å†…æœ‰æ›´æ–°ï¼ˆé¿å…åºŸå¼ƒrepoï¼‰
```

**Step 2**: ä¿®æ”¹ `src/prefilter/rule_filter.py`

æ‰¾åˆ° `_is_quality_github_repo` æ–¹æ³•ï¼ˆå¯èƒ½åœ¨RuleFilterç±»ä¸­ï¼‰ï¼Œå½“å‰å®ç°å¯èƒ½åªæ£€æŸ¥starsï¼š

```python
def _is_quality_github_repo(self, candidate: RawCandidate) -> bool:
    """GitHubä»“åº“è´¨é‡æ£€æŸ¥"""
    stars = candidate.github_stars or 0
    if stars < constants.PREFILTER_MIN_GITHUB_STARS:
        logger.debug(f"GitHub starsä¸è¶³: {candidate.title} ({stars})")
        return False
    return True
```

å®Œå…¨æ›¿æ¢ä¸ºå¤šç»´åº¦æ£€æŸ¥ç‰ˆæœ¬ï¼š

```python
def _is_quality_github_repo(self, candidate: RawCandidate) -> bool:
    """GitHubä»“åº“è´¨é‡æ£€æŸ¥ï¼ˆå¤šç»´åº¦ï¼‰

    æ£€æŸ¥ç»´åº¦:
    1. Starsæ•°é‡: è‡³å°‘10ä¸ªï¼ˆæ–°å…´Benchmarkå¯èƒ½è¾ƒå°‘ï¼‰
    2. æœ€è¿‘æ›´æ–°: 90å¤©å†…æœ‰æ´»åŠ¨ï¼ˆé¿å…åºŸå¼ƒé¡¹ç›®ï¼‰
    3. READMEé•¿åº¦: è‡³å°‘500å­—ç¬¦ï¼ˆé¿å…ç©ºrepoæˆ–å ä½é¡¹ç›®ï¼‰
    """
    from datetime import datetime, timedelta, timezone

    # 1. Starsæ£€æŸ¥ï¼ˆé™ä½é˜ˆå€¼åˆ°10ï¼‰
    stars = candidate.github_stars or 0
    if stars < constants.PREFILTER_MIN_GITHUB_STARS:
        logger.debug(
            f"GitHub starsä¸è¶³: {candidate.title} "
            f"({stars} < {constants.PREFILTER_MIN_GITHUB_STARS})"
        )
        return False

    # 2. æœ€è¿‘æ›´æ–°æ£€æŸ¥ï¼ˆ90å¤©å†…ï¼‰
    if candidate.publish_date:
        now = datetime.now(timezone.utc)
        days_since_update = (now - candidate.publish_date).days

        if days_since_update > constants.PREFILTER_RECENT_DAYS:
            logger.debug(
                f"GitHubæ›´æ–°æ—¶é—´è¿‡ä¹…: {candidate.title} "
                f"({days_since_update}å¤©å‰ï¼Œè¶…è¿‡{constants.PREFILTER_RECENT_DAYS}å¤©é˜ˆå€¼)"
            )
            return False

    # 3. READMEé•¿åº¦æ£€æŸ¥ï¼ˆé¿å…ç©ºrepoï¼‰
    abstract_length = len(candidate.abstract or "")
    if abstract_length < constants.PREFILTER_MIN_README_LENGTH:
        logger.debug(
            f"GitHub READMEè¿‡çŸ­: {candidate.title} "
            f"({abstract_length}å­—ç¬¦ < {constants.PREFILTER_MIN_README_LENGTH})"
        )
        return False

    logger.debug(
        f"GitHubä»“åº“é€šè¿‡é¢„ç­›é€‰: {candidate.title} "
        f"(stars={stars}, æ›´æ–°={days_since_update if candidate.publish_date else 'N/A'}å¤©å‰, "
        f"README={abstract_length}å­—ç¬¦)"
    )
    return True
```

**æ³¨æ„äº‹é¡¹**:
- å¦‚æœ `_is_quality_github_repo` æ–¹æ³•ä¸å­˜åœ¨ï¼Œéœ€è¦åœ¨ `RuleFilter` ç±»ä¸­æ–°å¢
- å¦‚æœ `apply` æ–¹æ³•ä¸­æ²¡æœ‰è°ƒç”¨GitHubæ£€æŸ¥ï¼Œéœ€è¦æ·»åŠ è°ƒç”¨é€»è¾‘ï¼š
  ```python
  if candidate.source == "github":
      if not self._is_quality_github_repo(candidate):
          continue
  ```

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. è¿è¡Œpipelineå¹¶æ£€æŸ¥é¢„ç­›é€‰ç»“æœ
python src/main.py 2>&1 | grep -A5 "é¢„ç­›é€‰å®Œæˆ"

# é¢„æœŸè¾“å‡ºç¤ºä¾‹:
# é¢„ç­›é€‰å®Œæˆ: ä¿ç•™5æ¡ (è¿‡æ»¤ç‡75.0%)
#
# å…¶ä¸­:
# - è¿‡æ»¤ç‡åº”è¯¥åœ¨ 70-90% èŒƒå›´ï¼ˆä¸å†æ˜¯100%ï¼‰
# - åº”è¯¥æœ‰ 1-5 æ¡GitHubå€™é€‰é€šè¿‡

# 2. æ£€æŸ¥è¯¦ç»†æ—¥å¿—ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
python src/main.py 2>&1 | grep "GitHub" | grep -E "(é€šè¿‡é¢„ç­›é€‰|starsä¸è¶³|æ›´æ–°æ—¶é—´è¿‡ä¹…|READMEè¿‡çŸ­)"

# é¢„æœŸ: çœ‹åˆ°å…·ä½“çš„è¿‡æ»¤åŸå› å’Œé€šè¿‡çš„å€™é€‰
```

#### Commitæ ¼å¼

```bash
git add src/common/constants.py src/prefilter/rule_filter.py
git commit -m "feat(prefilter): ä¼˜åŒ–GitHubé¢„ç­›é€‰è§„åˆ™ï¼Œè§£å†³100%è¿‡æ»¤é—®é¢˜

- é™ä½starsé˜ˆå€¼: 50 â†’ 10 (æ–°å…´Benchmarkå¯èƒ½starsè¾ƒå°‘)
- å¢åŠ READMEé•¿åº¦æ£€æŸ¥: â‰¥500å­—ç¬¦ (é¿å…ç©ºrepo)
- å¢åŠ æœ€è¿‘æ›´æ–°æ£€æŸ¥: 90å¤©å†…æœ‰æ´»åŠ¨ (é¿å…åºŸå¼ƒé¡¹ç›®)
- å¤šç»´åº¦è´¨é‡è¯„ä¼°æ›¿ä»£å•ä¸€starsæŒ‡æ ‡
- é¢„æœŸGitHubå€™é€‰é€šè¿‡ç‡: 10-30%"
```

---

### Task 3.3: å®ç°æ—¶é—´çª—å£è¿‡æ»¤

**ä¼˜å…ˆçº§**: ğŸŸ¡ P1ï¼ˆä¼˜åŒ–é‡‡é›†æ•ˆç‡ï¼‰
**é¢„è®¡è€—æ—¶**: 1-2å°æ—¶
**éš¾åº¦**: â­â­ (ä¸­ç­‰)

#### é—®é¢˜è¯Šæ–­

**å½“å‰çŠ¶æ€**:
- `src/common/constants.py` å·²å®šä¹‰æ—¶é—´çª—å£å¸¸é‡:
  - `GITHUB_LOOKBACK_DAYS = 30`
  - `HUGGINGFACE_LOOKBACK_DAYS = 14`
- **ä½†é‡‡é›†å™¨æœªä½¿ç”¨è¿™äº›å¸¸é‡**ï¼Œå¯¼è‡´é‡‡é›†æ‰€æœ‰å†å²æ•°æ®

**å½±å“**:
- GitHubé‡‡é›†å¯èƒ½è¿”å›å‡ ä¸ªæœˆå‰çš„repoï¼ˆå·²è¿‡æ—¶ï¼‰
- HuggingFaceé‡‡é›†è¿”å›å¤§é‡æ—§æ•°æ®é›†ï¼ˆå¢åŠ è¯„åˆ†æˆæœ¬ï¼‰
- æ— æ³•ä¿è¯"æ—¥æ›´"ç­–ç•¥çš„æ—¶æ•ˆæ€§

#### ä»£ç ä¿®æ”¹æ¸…å•

**Step 1**: ä¿®æ”¹ `src/collectors/github_collector.py`

æ‰¾åˆ° `_fetch_topic` æ–¹æ³•ï¼ˆæ„å»ºGitHubæœç´¢queryçš„åœ°æ–¹ï¼‰ï¼š

å½“å‰å®ç°å¯èƒ½ç±»ä¼¼ï¼š
```python
async def _fetch_topic(self, client: httpx.AsyncClient, topic: str) -> List[RawCandidate]:
    """è°ƒç”¨GitHubæœç´¢API"""
    params = {
        "q": f"{topic} benchmark in:name,description,readme",
        "sort": "stars",
        "order": "desc",
        "per_page": self.per_page,
    }
    # ... åç»­é€»è¾‘
```

ä¿®æ”¹ä¸ºå¢åŠ æ—¶é—´è¿‡æ»¤ï¼š
```python
from datetime import datetime, timedelta, timezone

async def _fetch_topic(self, client: httpx.AsyncClient, topic: str) -> List[RawCandidate]:
    """è°ƒç”¨GitHubæœç´¢APIï¼ˆå¢åŠ æ—¶é—´è¿‡æ»¤ï¼‰

    ä½¿ç”¨GitHubæœç´¢è¯­æ³• pushed:>YYYY-MM-DD è¿‡æ»¤æœ€è¿‘æ›´æ–°çš„ä»“åº“
    """
    # è®¡ç®—æ—¶é—´çª—å£ï¼ˆä»constantsä¸­è¯»å–ï¼‰
    lookback_date = datetime.now(timezone.utc) - timedelta(days=constants.GITHUB_LOOKBACK_DAYS)
    date_filter = lookback_date.strftime("%Y-%m-%d")  # æ ¼å¼: 2025-10-14

    params = {
        "q": f"{topic} benchmark in:name,description,readme pushed:>{date_filter}",  # å¢åŠ æ—¶é—´è¿‡æ»¤
        "sort": "stars",
        "order": "desc",
        "per_page": self.per_page,
    }

    logger.debug(
        f"GitHubæœç´¢query: {params['q']} "
        f"(æ—¶é—´çª—å£: æœ€è¿‘{constants.GITHUB_LOOKBACK_DAYS}å¤©)"
    )

    # ... åç»­é€»è¾‘ä¸å˜
```

**æ³¨æ„**: ç¡®ä¿åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥ `from src.common import constants`

**Step 2**: ä¿®æ”¹ `src/collectors/huggingface_collector.py`

æ‰¾åˆ° `collect` æ–¹æ³•ï¼ˆä¸»é‡‡é›†é€»è¾‘ï¼‰ï¼š

å½“å‰å®ç°å¯èƒ½åœ¨æœ€åç›´æ¥è¿”å› `all_candidates`ï¼š
```python
async def collect(self) -> List[RawCandidate]:
    """é‡‡é›†HuggingFaceæ•°æ®é›†"""
    all_candidates = []

    # ... é‡‡é›†é€»è¾‘ ...

    logger.info("HuggingFaceé‡‡é›†å®Œæˆ,å€™é€‰æ•°%d", len(all_candidates))
    return all_candidates
```

ä¿®æ”¹ä¸ºå¢åŠ æ—¶é—´è¿‡æ»¤åå¤„ç†ï¼š
```python
from datetime import datetime, timedelta, timezone

async def collect(self) -> List[RawCandidate]:
    """é‡‡é›†HuggingFaceæ•°æ®é›†ï¼ˆå¢åŠ æ—¶é—´è¿‡æ»¤ï¼‰

    é‡‡é›†åæ ¹æ®publish_dateè¿‡æ»¤ï¼Œåªä¿ç•™æœ€è¿‘Nå¤©çš„æ•°æ®é›†
    """
    all_candidates = []

    # ... åŸæœ‰é‡‡é›†é€»è¾‘ ...

    # æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆé‡‡é›†åå¤„ç†ï¼‰
    lookback_date = datetime.now(timezone.utc) - timedelta(days=constants.HUGGINGFACE_LOOKBACK_DAYS)

    filtered_candidates = []
    for candidate in all_candidates:
        if candidate.publish_date and candidate.publish_date >= lookback_date:
            filtered_candidates.append(candidate)
        else:
            # è®°å½•è¢«è¿‡æ»¤çš„å€™é€‰ï¼ˆè°ƒè¯•ç”¨ï¼‰
            if candidate.publish_date:
                days_old = (datetime.now(timezone.utc) - candidate.publish_date).days
                logger.debug(
                    f"HuggingFaceè¿‡æ»¤æ—§æ•°æ®é›†: {candidate.title} "
                    f"(å‘å¸ƒäº{days_old}å¤©å‰ï¼Œè¶…è¿‡{constants.HUGGINGFACE_LOOKBACK_DAYS}å¤©çª—å£)"
                )

    logger.info(
        "HuggingFaceé‡‡é›†å®Œæˆ: åŸå§‹%dæ¡ â†’ æ—¶é—´è¿‡æ»¤å%dæ¡ (çª—å£: %då¤©)",
        len(all_candidates),
        len(filtered_candidates),
        constants.HUGGINGFACE_LOOKBACK_DAYS,
    )
    return filtered_candidates
```

**æ³¨æ„**:
- ç¡®ä¿åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥ `from src.common import constants`
- HuggingFace APIå¯èƒ½ä¸æ”¯æŒç›´æ¥çš„æ—¶é—´è¿‡æ»¤ï¼Œæ‰€ä»¥é‡‡ç”¨åå¤„ç†æ–¹å¼

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. è¿è¡Œpipelineï¼Œæ£€æŸ¥é‡‡é›†æ—¥å¿—
python src/main.py 2>&1 | grep -E "(GitHub|HuggingFace)é‡‡é›†å®Œæˆ"

# é¢„æœŸè¾“å‡ºç¤ºä¾‹:
# GitHubCollectoré‡‡é›†å®Œæˆ: 8æ¡ (æ—¶é—´çª—å£: æœ€è¿‘30å¤©)
# HuggingFaceé‡‡é›†å®Œæˆ: åŸå§‹25æ¡ â†’ æ—¶é—´è¿‡æ»¤å12æ¡ (çª—å£: 14å¤©)

# 2. å¯¹æ¯”ä¿®æ”¹å‰åçš„é‡‡é›†æ•°é‡
# é¢„æœŸ: ä¿®æ”¹åé‡‡é›†æ•°é‡åº”è¯¥å‡å°‘ï¼ˆåªé‡‡é›†æœ€è¿‘Nå¤©çš„æ•°æ®ï¼‰

# 3. æ£€æŸ¥æ—¶é—´è¿‡æ»¤æ˜¯å¦ç”Ÿæ•ˆ
python src/main.py 2>&1 | grep "æ—¶é—´çª—å£"

# é¢„æœŸ: çœ‹åˆ°æ—¶é—´çª—å£ç›¸å…³çš„æ—¥å¿—
```

#### Commitæ ¼å¼

```bash
git add src/collectors/github_collector.py src/collectors/huggingface_collector.py
git commit -m "feat(collectors): å®ç°æ—¶é—´çª—å£è¿‡æ»¤

- GitHub: ä½¿ç”¨pushed:>dateè¯­æ³•è¿‡æ»¤30å¤©å†…æ›´æ–°çš„ä»“åº“
- HuggingFace: é‡‡é›†åè¿‡æ»¤14å¤©å†…çš„æ•°æ®é›†
- æå‡æ•°æ®æ—¶æ•ˆæ€§ï¼Œå‡å°‘æ— æ•ˆé‡‡é›†å’Œè¯„åˆ†æˆæœ¬
- æ”¯æŒæ—¥æ›´ç­–ç•¥ï¼Œé¿å…é‡å¤å¤„ç†å†å²æ•°æ®"
```

---

### Task 3.4: åˆ›å»ºæ—¥å¿—åˆ†æå·¥å…·

**ä¼˜å…ˆçº§**: ğŸŸ¢ P2ï¼ˆè¿ç»´è¾…åŠ©å·¥å…·ï¼‰
**é¢„è®¡è€—æ—¶**: 1å°æ—¶
**éš¾åº¦**: â­ (ç®€å•)

#### éœ€æ±‚è¯´æ˜

åˆ›å»º `scripts/analyze_logs.py`ï¼Œç”¨äºåˆ†ææ¯æ—¥é‡‡é›†æ•ˆæœï¼Œè¾“å‡ºæ ¼å¼åŒ–æŠ¥å‘Šã€‚

**åŠŸèƒ½éœ€æ±‚**:
1. è§£ææ—¥å¿—æ–‡ä»¶ï¼Œæå–å…³é”®ç»Ÿè®¡æ•°æ®
2. ç”Ÿæˆç¾è§‚çš„æ–‡æœ¬æŠ¥å‘Š
3. æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ—¥å¿—æ–‡ä»¶

**ç»Ÿè®¡ç»´åº¦**:
- é‡‡é›†ç»Ÿè®¡: å„æ•°æ®æºé‡‡é›†æ•°é‡
- å»é‡ç»Ÿè®¡: é‡å¤è¿‡æ»¤ã€æ–°å‘ç°æ•°é‡
- é¢„ç­›é€‰ç»Ÿè®¡: è¾“å‡ºæ•°é‡ã€è¿‡æ»¤ç‡
- è¯„åˆ†ç»Ÿè®¡: å¹³å‡åˆ†
- ä¼˜å…ˆçº§ç»Ÿè®¡: é«˜/ä¸­/ä½ä¼˜å…ˆçº§æ•°é‡

#### å®Œæ•´ä»£ç å®ç°

**æ–‡ä»¶**: `scripts/analyze_logs.py`

```python
"""æ—¥å¿—åˆ†æå·¥å…·

è§£æBenchScopeæ—¥å¿—æ–‡ä»¶ï¼Œç”Ÿæˆæ ¼å¼åŒ–çš„ç»Ÿè®¡æŠ¥å‘Š

ç”¨æ³•:
    python scripts/analyze_logs.py logs/benchscope.log
    python scripts/analyze_logs.py logs/test_20251113_143022.log

è¾“å‡ºç¤ºä¾‹:
    ============================================================
    BenchScope æ—¥å¿—åˆ†ææŠ¥å‘Š
    ============================================================

    ## æ•°æ®é‡‡é›†
      ArxivCollector: 12æ¡
      GitHubCollector: 8æ¡
      HuggingFaceCollector: 15æ¡

    ## å»é‡
      é‡å¤è¿‡æ»¤: 3æ¡
      æ–°å‘ç°: 32æ¡

    ## é¢„ç­›é€‰
      è¾“å‡º: 8æ¡
      è¿‡æ»¤ç‡: 75.0%

    ## è¯„åˆ†
      å¹³å‡åˆ†: 6.81/10

    ## ä¼˜å…ˆçº§
      é«˜: 2æ¡
      ä¸­: 5æ¡
      ä½: 1æ¡

    ============================================================
"""
import re
import sys
from collections import defaultdict
from pathlib import Path


def parse_log_file(log_path: Path) -> dict:
    """è§£ææ—¥å¿—æ–‡ä»¶ï¼Œæå–ç»Ÿè®¡æ•°æ®

    Args:
        log_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«å„ç»´åº¦ç»Ÿè®¡æ•°æ®çš„å­—å…¸
    """
    stats = {
        "é‡‡é›†ç»Ÿè®¡": {},
        "å»é‡ç»Ÿè®¡": {},
        "é¢„ç­›é€‰ç»Ÿè®¡": {},
        "è¯„åˆ†ç»Ÿè®¡": {},
        "ä¼˜å…ˆçº§ç»Ÿè®¡": {},
    }

    with open(log_path, encoding="utf-8") as f:
        for line in f:
            # é‡‡é›†ç»Ÿè®¡: åŒ¹é… "âœ“ ArxivCollector: 12æ¡"
            if match := re.search(r"âœ“ (\w+Collector): (\d+)æ¡", line):
                collector, count = match.groups()
                stats["é‡‡é›†ç»Ÿè®¡"][collector] = int(count)

            # å»é‡ç»Ÿè®¡: åŒ¹é… "å»é‡å®Œæˆ: è¿‡æ»¤3æ¡é‡å¤,ä¿ç•™32æ¡æ–°å‘ç°"
            if match := re.search(r"å»é‡å®Œæˆ: è¿‡æ»¤(\d+)æ¡é‡å¤,ä¿ç•™(\d+)æ¡æ–°å‘ç°", line):
                duplicate, new = match.groups()
                stats["å»é‡ç»Ÿè®¡"] = {"é‡å¤": int(duplicate), "æ–°å‘ç°": int(new)}

            # é¢„ç­›é€‰ç»Ÿè®¡: åŒ¹é… "é¢„ç­›é€‰å®Œæˆ: ä¿ç•™8æ¡ (è¿‡æ»¤ç‡75.0%)"
            if match := re.search(r"é¢„ç­›é€‰å®Œæˆ: ä¿ç•™(\d+)æ¡ \(è¿‡æ»¤ç‡([\d.]+)%\)", line):
                output, filter_rate = match.groups()
                stats["é¢„ç­›é€‰ç»Ÿè®¡"] = {"è¾“å‡º": int(output), "è¿‡æ»¤ç‡": float(filter_rate)}

            # è¯„åˆ†ç»Ÿè®¡: åŒ¹é… "å¹³å‡åˆ†: 6.81/10"
            if match := re.search(r"å¹³å‡åˆ†: ([\d.]+)/10", line):
                stats["è¯„åˆ†ç»Ÿè®¡"]["å¹³å‡åˆ†"] = float(match.group(1))

            # ä¼˜å…ˆçº§ç»Ÿè®¡: åŒ¹é… "é«˜ä¼˜å…ˆçº§: 2æ¡" "ä¸­ä¼˜å…ˆçº§: 5æ¡" "ä½ä¼˜å…ˆçº§: 1æ¡"
            if match := re.search(r"(é«˜|ä¸­|ä½)ä¼˜å…ˆçº§: (\d+)æ¡", line):
                priority, count = match.groups()
                stats["ä¼˜å…ˆçº§ç»Ÿè®¡"][priority] = int(count)

    return stats


def generate_report(stats: dict) -> str:
    """ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š

    Args:
        stats: ç»Ÿè®¡æ•°æ®å­—å…¸

    Returns:
        æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    lines = [
        "=" * 60,
        "BenchScope æ—¥å¿—åˆ†ææŠ¥å‘Š",
        "=" * 60,
        "",
    ]

    # æ•°æ®é‡‡é›†
    if stats["é‡‡é›†ç»Ÿè®¡"]:
        lines.append("## æ•°æ®é‡‡é›†")
        for collector, count in stats["é‡‡é›†ç»Ÿè®¡"].items():
            lines.append(f"  {collector}: {count}æ¡")
        lines.append("")

    # å»é‡
    if stats["å»é‡ç»Ÿè®¡"]:
        lines.extend([
            "## å»é‡",
            f"  é‡å¤è¿‡æ»¤: {stats['å»é‡ç»Ÿè®¡']['é‡å¤']}æ¡",
            f"  æ–°å‘ç°: {stats['å»é‡ç»Ÿè®¡']['æ–°å‘ç°']}æ¡",
            "",
        ])

    # é¢„ç­›é€‰
    if stats["é¢„ç­›é€‰ç»Ÿè®¡"]:
        lines.extend([
            "## é¢„ç­›é€‰",
            f"  è¾“å‡º: {stats['é¢„ç­›é€‰ç»Ÿè®¡']['è¾“å‡º']}æ¡",
            f"  è¿‡æ»¤ç‡: {stats['é¢„ç­›é€‰ç»Ÿè®¡']['è¿‡æ»¤ç‡']:.1f}%",
            "",
        ])

    # è¯„åˆ†
    if stats["è¯„åˆ†ç»Ÿè®¡"]:
        avg_score = stats["è¯„åˆ†ç»Ÿè®¡"].get("å¹³å‡åˆ†", 0)
        lines.extend([
            "## è¯„åˆ†",
            f"  å¹³å‡åˆ†: {avg_score:.2f}/10",
            "",
        ])

    # ä¼˜å…ˆçº§
    if stats["ä¼˜å…ˆçº§ç»Ÿè®¡"]:
        lines.append("## ä¼˜å…ˆçº§")
        for priority in ["é«˜", "ä¸­", "ä½"]:
            if priority in stats["ä¼˜å…ˆçº§ç»Ÿè®¡"]:
                count = stats["ä¼˜å…ˆçº§ç»Ÿè®¡"][priority]
                lines.append(f"  {priority}: {count}æ¡")
        lines.append("")

    lines.extend(["=" * 60])
    return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œåˆ†æ"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python scripts/analyze_logs.py <æ—¥å¿—æ–‡ä»¶>")
        print("\nç¤ºä¾‹:")
        print("  python scripts/analyze_logs.py logs/benchscope.log")
        print("  python scripts/analyze_logs.py logs/test_20251113_143022.log")
        sys.exit(1)

    log_path = Path(sys.argv[1])
    if not log_path.exists():
        print(f"é”™è¯¯: æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ - {log_path}")
        sys.exit(1)

    # è§£ææ—¥å¿—å¹¶ç”ŸæˆæŠ¥å‘Š
    stats = parse_log_file(log_path)
    report = generate_report(stats)
    print(report)


if __name__ == "__main__":
    main()
```

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. æµ‹è¯•è„šæœ¬è¯­æ³•
python -m py_compile scripts/analyze_logs.py

# é¢„æœŸ: æ— è¾“å‡ºï¼ˆç¼–è¯‘æˆåŠŸï¼‰

# 2. æµ‹è¯•å¸®åŠ©ä¿¡æ¯
python scripts/analyze_logs.py

# é¢„æœŸè¾“å‡º:
# ç”¨æ³•: python scripts/analyze_logs.py <æ—¥å¿—æ–‡ä»¶>
#
# ç¤ºä¾‹:
#   python scripts/analyze_logs.py logs/benchscope.log
#   python scripts/analyze_logs.py logs/test_20251113_143022.log

# 3. è¿è¡ŒçœŸå®æ—¥å¿—åˆ†æ
python src/main.py 2>&1 | tee logs/test_$(date +%Y%m%d_%H%M%S).log
python scripts/analyze_logs.py logs/test_*.log

# é¢„æœŸ: è¾“å‡ºæ ¼å¼åŒ–çš„ç»Ÿè®¡æŠ¥å‘Šï¼ˆå¦‚æ–‡æ¡£å¼€å¤´ç¤ºä¾‹æ‰€ç¤ºï¼‰

# 4. æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
python scripts/analyze_logs.py logs/nonexistent.log

# é¢„æœŸè¾“å‡º:
# é”™è¯¯: æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ - logs/nonexistent.log
```

#### Commitæ ¼å¼

```bash
git add scripts/analyze_logs.py
git commit -m "feat(scripts): åˆ›å»ºæ—¥å¿—åˆ†æå·¥å…·

- è§£æpipelineæ—¥å¿—æ–‡ä»¶ï¼Œæå–å…³é”®ç»Ÿè®¡æ•°æ®
- ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Šï¼šé‡‡é›†/å»é‡/é¢„ç­›é€‰/è¯„åˆ†/ä¼˜å…ˆçº§
- æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ—¥å¿—æ–‡ä»¶
- ç”¨äºæ¯æ—¥è¿è¡Œæ•ˆæœåˆ†æå’Œé—®é¢˜æ’æŸ¥"
```

---

### Task 3.5: è°ƒæ•´è¯„åˆ†æƒé‡ï¼ˆå¯é€‰ï¼‰

**ä¼˜å…ˆçº§**: ğŸŸ¢ P3ï¼ˆå¯é€‰ï¼Œæ ¹æ®å®é™…æ•ˆæœå†³å®šï¼‰
**é¢„è®¡è€—æ—¶**: 30åˆ†é’Ÿ
**éš¾åº¦**: â­ (ç®€å•)

#### é—®é¢˜è¯Šæ–­

**å½“å‰æƒé‡**:
```
æ´»è·ƒåº¦:     25%  (GitHub stars/commits)
å¯å¤ç°æ€§:   30%  (ä»£ç /æ•°æ®å¼€æºçŠ¶æ€)
è®¸å¯åˆè§„:   20%  (MIT/Apache/BSD)
ä»»åŠ¡æ–°é¢–æ€§: 15%  (ä¸å·²æœ‰ä»»åŠ¡ç›¸ä¼¼åº¦)
MGXé€‚é…åº¦:  10%  (ä¸MetaGPTä¸šåŠ¡ç›¸å…³æ€§)
```

**æ½œåœ¨é—®é¢˜**:
- æ´»è·ƒåº¦25%æƒé‡è¿‡é«˜ï¼ˆGitHub starsæ³¢åŠ¨å¤§ï¼Œæ–°é¡¹ç›®ä¸å…¬å¹³ï¼‰
- MGXé€‚é…åº¦10%æƒé‡è¿‡ä½ï¼ˆè¿™æ˜¯æ ¸å¿ƒä¸šåŠ¡ç›¸å…³æ€§æŒ‡æ ‡ï¼‰

**å»ºè®®è°ƒæ•´**:
```
æ´»è·ƒåº¦:     25% â†’ 20%  (é™ä½5%)
å¯å¤ç°æ€§:   30% â†’ 30%  (ä¿æŒ)
è®¸å¯åˆè§„:   20% â†’ 15%  (é™ä½5%)
ä»»åŠ¡æ–°é¢–æ€§: 15% â†’ 15%  (ä¿æŒ)
MGXé€‚é…åº¦:  10% â†’ 20%  (æé«˜10%)
```

#### ä»£ç ä¿®æ”¹æ¸…å•

**æ–‡ä»¶**: `src/scorer/llm_scorer.py`

æ‰¾åˆ° `_build_prompt` æ–¹æ³•ä¸­çš„è¯„åˆ†ç»´åº¦è¯´æ˜éƒ¨åˆ†ï¼š

å½“å‰å¯èƒ½ç±»ä¼¼ï¼š
```python
è¯·åŸºäºä»¥ä¸‹ç»´åº¦è¯„åˆ†(0-10åˆ†):

1. æ´»è·ƒåº¦(25%): GitHub stars/è¿‘æœŸcommits/ç¤¾åŒºå‚ä¸åº¦
2. å¯å¤ç°æ€§(30%): ä»£ç /æ•°æ®é›†å¼€æºçŠ¶æ€,å¤ç°æ–‡æ¡£å®Œæ•´æ€§
3. è®¸å¯åˆè§„(20%): MIT/Apache/BSDç­‰å•†ä¸šå‹å¥½è®¸å¯
4. ä»»åŠ¡æ–°é¢–æ€§(15%): ä¸å·²æœ‰Benchmarkçš„å·®å¼‚åº¦,åˆ›æ–°æ€§
5. MGXé€‚é…åº¦(10%): ä¸MetaGPTå¤šagent/ä»£ç ç”Ÿæˆ/å·¥å…·ä½¿ç”¨çš„ç›¸å…³æ€§
```

ä¿®æ”¹ä¸ºï¼š
```python
è¯·åŸºäºä»¥ä¸‹ç»´åº¦è¯„åˆ†(0-10åˆ†):

1. æ´»è·ƒåº¦(20%): GitHub stars/è¿‘æœŸcommits/ç¤¾åŒºå‚ä¸åº¦
   - è€ƒè™‘é¡¹ç›®æˆç†Ÿåº¦ï¼Œä½†ä¸è¿‡åˆ†æƒ©ç½šæ–°é¡¹ç›®

2. å¯å¤ç°æ€§(30%): ä»£ç /æ•°æ®é›†å¼€æºçŠ¶æ€,å¤ç°æ–‡æ¡£å®Œæ•´æ€§
   - å¼€æºä»£ç åº“ã€å…¬å¼€æ•°æ®é›†ã€è¯¦ç»†æ–‡æ¡£ä¼˜å…ˆ

3. è®¸å¯åˆè§„(15%): MIT/Apache/BSDç­‰å•†ä¸šå‹å¥½è®¸å¯
   - å•†ä¸šå‹å¥½è®¸å¯åŠ åˆ†ï¼ŒGPLç­‰é™åˆ¶æ€§è®¸å¯å‡åˆ†

4. ä»»åŠ¡æ–°é¢–æ€§(15%): ä¸å·²æœ‰Benchmarkçš„å·®å¼‚åº¦,åˆ›æ–°æ€§
   - å¡«è¡¥ç°æœ‰Benchmarkç©ºç™½çš„ä»»åŠ¡åŠ åˆ†

5. MGXé€‚é…åº¦(20%): ä¸MetaGPTå¤šagent/ä»£ç ç”Ÿæˆ/å·¥å…·ä½¿ç”¨çš„ç›¸å…³æ€§
   - é‡ç‚¹å…³æ³¨ï¼šå¤šagentåä½œã€ä»£ç ç”Ÿæˆã€Web/GUIäº¤äº’ã€å·¥å…·ä½¿ç”¨
   - è¿™æ˜¯æ ¸å¿ƒä¸šåŠ¡ç›¸å…³æ€§æŒ‡æ ‡ï¼Œæƒé‡æé«˜åˆ°20%
```

**æ³¨æ„**:
- å¦‚æœpromptä¸­è¿˜æœ‰æƒé‡è®¡ç®—å…¬å¼ï¼Œä¹Ÿéœ€è¦åŒæ­¥æ›´æ–°ï¼š
  ```python
  total_score = (
      activity_score * 0.20 +
      reproducibility_score * 0.30 +
      license_score * 0.15 +
      novelty_score * 0.15 +
      relevance_score * 0.20
  )
  ```

#### é‡è¦æé†’

**æƒé‡è°ƒæ•´ä¼šå½±å“å†å²è¯„åˆ†çš„å¯æ¯”æ€§**:
1. ä¿®æ”¹å‰çš„å€™é€‰ï¼ˆæ€»åˆ†åŸºäºæ—§æƒé‡ï¼‰
2. ä¿®æ”¹åçš„å€™é€‰ï¼ˆæ€»åˆ†åŸºäºæ–°æƒé‡ï¼‰
3. ä¸¤è€…åˆ†æ•°ä¸èƒ½ç›´æ¥å¯¹æ¯”

**å»ºè®®ç­–ç•¥**:
- **Option Aï¼ˆæ¨èï¼‰**: æ¸…ç©ºRedisç¼“å­˜ï¼Œé‡æ–°è¯„åˆ†æ‰€æœ‰å€™é€‰
  ```bash
  redis-cli FLUSHALL
  ```
- **Option B**: åœ¨é£ä¹¦è¡¨æ ¼ä¸­å¢åŠ "è¯„åˆ†ç‰ˆæœ¬"å­—æ®µï¼Œæ ‡è®°v1/v2

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. æ¸…ç©ºRedisç¼“å­˜ï¼ˆå¦‚æœæ‰§è¡ŒOption Aï¼‰
redis-cli FLUSHALL

# é¢„æœŸè¾“å‡º: OK

# 2. è¿è¡Œpipelineï¼Œæ£€æŸ¥å¹³å‡åˆ†å˜åŒ–
python src/main.py 2>&1 | grep "å¹³å‡åˆ†"

# é¢„æœŸ:
# - MGXç›¸å…³å€™é€‰ï¼ˆå¦‚multi-agent benchmarkï¼‰åˆ†æ•°åº”è¯¥æå‡
# - æ´»è·ƒåº¦ä¸€èˆ¬ä½†MGXç›¸å…³æ€§é«˜çš„å€™é€‰åˆ†æ•°åº”è¯¥æå‡

# 3. å¯¹æ¯”ä¿®æ”¹å‰åçš„è¯„åˆ†ç»“æœ
# æ‰‹åŠ¨æ£€æŸ¥å‡ ä¸ªå…¸å‹å€™é€‰çš„åˆ†æ•°å˜åŒ–
```

#### Commitæ ¼å¼

```bash
git add src/scorer/llm_scorer.py
git commit -m "feat(scorer): è°ƒæ•´è¯„åˆ†æƒé‡ï¼Œæå‡MGXé€‚é…åº¦é‡è¦æ€§

- æ´»è·ƒåº¦: 25% â†’ 20% (é™ä½å¯¹æ–°é¡¹ç›®çš„æƒ©ç½š)
- è®¸å¯åˆè§„: 20% â†’ 15% (é™ä½è®¸å¯è¯æƒé‡)
- MGXé€‚é…åº¦: 10% â†’ 20% (æå‡æ ¸å¿ƒä¸šåŠ¡ç›¸å…³æ€§æƒé‡)
- æ›´åŠ é‡è§†å¤šagent/ä»£ç ç”Ÿæˆ/å·¥å…·ä½¿ç”¨ç›¸å…³çš„Benchmark
- æ³¨æ„: éœ€æ¸…ç©ºRedisç¼“å­˜é‡æ–°è¯„åˆ†"
```

---

### Phase 3 æ€»ç»“æµ‹è¯•

**å®Œæˆæ‰€æœ‰Taskåï¼Œæ‰§è¡Œä»¥ä¸‹æµ‹è¯•**:

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate
export PYTHONPATH=.

# 2. æ¸…ç©ºRedisç¼“å­˜ï¼ˆå¦‚æœä¿®æ”¹äº†è¯„åˆ†æƒé‡ï¼‰
redis-cli FLUSHALL

# 3. æ¸…ç©ºé£ä¹¦è¡¨æ ¼ï¼ˆå¯é€‰ï¼Œé‡æ–°å¼€å§‹ï¼‰
python scripts/clear_feishu_table.py

# 4. è¿è¡Œå®Œæ•´pipeline
python src/main.py 2>&1 | tee logs/phase3_test_$(date +%Y%m%d_%H%M%S).log

# 5. åˆ†ææ—¥å¿—
python scripts/analyze_logs.py logs/phase3_test_*.log

# 6. æ£€æŸ¥å…³é”®æŒ‡æ ‡
grep "GitHub" logs/phase3_test_*.log | grep -E "(é‡‡é›†|é¢„ç­›é€‰)"
```

**é¢„æœŸç»“æœ**:
- âœ… GitHubé‡‡é›†æ•°é‡: 5-15æ¡ï¼ˆ30å¤©çª—å£ï¼‰
- âœ… GitHubé¢„ç­›é€‰é€šè¿‡: 1-5æ¡ï¼ˆ10-30%é€šè¿‡ç‡ï¼Œä¸å†æ˜¯100%ï¼‰
- âœ… æ— PwCé”™è¯¯æ—¥å¿—
- âœ… æ—¥å¿—åˆ†æå·¥å…·æ­£å¸¸è¾“å‡º
- âœ… å¹³å‡åˆ†åœ¨åˆç†èŒƒå›´ï¼ˆ6-8åˆ†ï¼‰

---

## Phase 4: ç‰ˆæœ¬è·Ÿè¸ª

**ç›®æ ‡**: ç›‘æ§å·²å…¥åº“Benchmarkçš„æ›´æ–°ï¼ŒåŠæ—¶æ¨é€ç‰ˆæœ¬å˜åŒ–
**é¢„è®¡è€—æ—¶**: 3-4å¤©
**ä¼˜å…ˆçº§**: ğŸŸ¡ ä¸­ï¼ˆä»·å€¼é«˜ä½†éç´§æ€¥ï¼‰

---

### Task 4.1: GitHub Releaseç›‘æ§

**ä¼˜å…ˆçº§**: ğŸŸ¡ P1
**é¢„è®¡è€—æ—¶**: 2-3å°æ—¶
**éš¾åº¦**: â­â­â­ (ä¸­é«˜)

#### éœ€æ±‚è¯´æ˜

ç›‘æ§å·²å…¥åº“çš„GitHubä»“åº“ï¼Œå½“æœ‰æ–°Releaseæ—¶æ¨é€é€šçŸ¥ã€‚

**åŠŸèƒ½éœ€æ±‚**:
1. ä»é£ä¹¦Bitableè¯»å–æ‰€æœ‰GitHubç±»å‹çš„å€™é€‰
2. æŸ¥è¯¢GitHub APIè·å–æœ€æ–°Releaseä¿¡æ¯
3. å¯¹æ¯”æœ¬åœ°å­˜å‚¨çš„ç‰ˆæœ¬ï¼Œè¯†åˆ«æ–°Release
4. æ¨é€é£ä¹¦é€šçŸ¥ï¼ˆæ ‡é¢˜+ç‰ˆæœ¬å·+æ›´æ–°è¯´æ˜ï¼‰

**æ•°æ®æ¨¡å‹**:
éœ€è¦åœ¨SQLiteä¸­æ–°å¢è¡¨ `github_releases`:
```sql
CREATE TABLE github_releases (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    repo_url TEXT NOT NULL,          -- GitHubä»“åº“URL
    tag_name TEXT NOT NULL,          -- Release tag (e.g., v1.2.0)
    published_at TIMESTAMP NOT NULL, -- å‘å¸ƒæ—¶é—´
    release_notes TEXT,              -- Releaseè¯´æ˜
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(repo_url, tag_name)       -- åŒä¸€repo+tagå”¯ä¸€
);
```

#### ä»£ç å®ç°æ¸…å•

**Step 1**: åˆ›å»ºæ•°æ®æ¨¡å‹ `src/models.py`

åœ¨æ–‡ä»¶æœ«å°¾å¢åŠ ï¼š
```python
@dataclass
class GitHubRelease:
    """GitHub Releaseç‰ˆæœ¬ä¿¡æ¯"""
    repo_url: str                      # ä»“åº“URL
    tag_name: str                      # ç‰ˆæœ¬tag
    published_at: datetime             # å‘å¸ƒæ—¶é—´
    release_notes: str                 # Releaseè¯´æ˜
    html_url: str                      # Releaseé¡µé¢URL
```

**Step 2**: åˆ›å»ºç‰ˆæœ¬è·Ÿè¸ªå™¨ `src/tracker/github_tracker.py`

```python
"""GitHub Releaseç‰ˆæœ¬è·Ÿè¸ªå™¨"""
from __future__ import annotations

import logging
import re
import sqlite3
from datetime import datetime, timezone
from pathlib import Path
from typing import List

import httpx

from src.models import GitHubRelease

logger = logging.getLogger(__name__)


class GitHubReleaseTracker:
    """ç›‘æ§GitHubä»“åº“çš„æ–°Release"""

    def __init__(self, db_path: str = "fallback.db", github_token: str | None = None):
        """
        Args:
            db_path: SQLiteæ•°æ®åº“è·¯å¾„
            github_token: GitHub Personal Access Token (å¯é€‰ï¼Œæé«˜APIé™é¢)
        """
        self.db_path = Path(db_path)
        self.github_token = github_token
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS github_releases (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    repo_url TEXT NOT NULL,
                    tag_name TEXT NOT NULL,
                    published_at TIMESTAMP NOT NULL,
                    release_notes TEXT,
                    html_url TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(repo_url, tag_name)
                )
            """)
            conn.commit()
        logger.info("GitHub Releaseè·Ÿè¸ªæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    def _extract_owner_repo(self, github_url: str) -> tuple[str, str] | None:
        """ä»GitHub URLæå–ownerå’Œrepoåç§°

        æ”¯æŒæ ¼å¼:
        - https://github.com/owner/repo
        - https://github.com/owner/repo.git
        - github.com/owner/repo

        Returns:
            (owner, repo) æˆ– None
        """
        pattern = r"github\.com/([^/]+)/([^/\.]+)"
        if match := re.search(pattern, github_url):
            return match.group(1), match.group(2)
        return None

    async def fetch_latest_release(self, repo_url: str) -> GitHubRelease | None:
        """æŸ¥è¯¢GitHubä»“åº“çš„æœ€æ–°Release

        Args:
            repo_url: GitHubä»“åº“URL

        Returns:
            æœ€æ–°Releaseå¯¹è±¡ï¼Œå¦‚æœæ— Releaseåˆ™è¿”å›None
        """
        if not (pair := self._extract_owner_repo(repo_url)):
            logger.warning(f"æ— æ³•è§£æGitHub URL: {repo_url}")
            return None

        owner, repo = pair
        api_url = f"https://api.github.com/repos/{owner}/{repo}/releases/latest"

        headers = {"Accept": "application/vnd.github+json"}
        if self.github_token:
            headers["Authorization"] = f"Bearer {self.github_token}"

        try:
            async with httpx.AsyncClient(timeout=10) as client:
                resp = await client.get(api_url, headers=headers)
                resp.raise_for_status()
                data = resp.json()

                return GitHubRelease(
                    repo_url=repo_url,
                    tag_name=data["tag_name"],
                    published_at=datetime.fromisoformat(data["published_at"].replace("Z", "+00:00")),
                    release_notes=data.get("body", "")[:1000],  # é™åˆ¶1000å­—ç¬¦
                    html_url=data["html_url"],
                )
        except httpx.HTTPStatusError as exc:
            if exc.response.status_code == 404:
                logger.debug(f"ä»“åº“æ— Release: {repo_url}")
            else:
                logger.warning(f"æŸ¥è¯¢GitHub Releaseå¤±è´¥: {repo_url} - {exc}")
            return None
        except Exception as exc:  # noqa: BLE001
            logger.error(f"æŸ¥è¯¢GitHub Releaseå¼‚å¸¸: {repo_url} - {exc}")
            return None

    def is_new_release(self, release: GitHubRelease) -> bool:
        """æ£€æŸ¥Releaseæ˜¯å¦ä¸ºæ–°ç‰ˆæœ¬ï¼ˆæœªè®°å½•è¿‡ï¼‰"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT COUNT(*) FROM github_releases WHERE repo_url = ? AND tag_name = ?",
                (release.repo_url, release.tag_name),
            )
            count = cursor.fetchone()[0]
            return count == 0

    def save_release(self, release: GitHubRelease):
        """ä¿å­˜Releaseåˆ°æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                INSERT OR IGNORE INTO github_releases
                (repo_url, tag_name, published_at, release_notes, html_url)
                VALUES (?, ?, ?, ?, ?)
                """,
                (
                    release.repo_url,
                    release.tag_name,
                    release.published_at.isoformat(),
                    release.release_notes,
                    release.html_url,
                ),
            )
            conn.commit()
        logger.info(f"ä¿å­˜GitHub Release: {release.repo_url} - {release.tag_name}")

    async def check_updates(self, repo_urls: List[str]) -> List[GitHubRelease]:
        """æ£€æŸ¥å¤šä¸ªä»“åº“çš„æ›´æ–°

        Args:
            repo_urls: GitHubä»“åº“URLåˆ—è¡¨

        Returns:
            æ–°Releaseåˆ—è¡¨
        """
        new_releases = []

        for repo_url in repo_urls:
            logger.debug(f"æ£€æŸ¥GitHubä»“åº“: {repo_url}")
            release = await self.fetch_latest_release(repo_url)

            if release and self.is_new_release(release):
                logger.info(f"å‘ç°æ–°Release: {repo_url} - {release.tag_name}")
                self.save_release(release)
                new_releases.append(release)

        logger.info(f"GitHub Releaseæ£€æŸ¥å®Œæˆ: å…±{len(repo_urls)}ä¸ªä»“åº“, å‘ç°{len(new_releases)}ä¸ªæ–°ç‰ˆæœ¬")
        return new_releases
```

**Step 3**: åˆ›å»ºè·Ÿè¸ªä»»åŠ¡è„šæœ¬ `scripts/track_github_releases.py`

```python
"""GitHub Releaseç‰ˆæœ¬è·Ÿè¸ªä»»åŠ¡

ä»é£ä¹¦Bitableè¯»å–æ‰€æœ‰GitHubä»“åº“ï¼Œæ£€æŸ¥æ–°Releaseå¹¶æ¨é€é€šçŸ¥

ç”¨æ³•:
    python scripts/track_github_releases.py
"""
import asyncio
import logging
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import get_settings
from src.notifier import FeishuNotifier
from src.storage import StorageManager
from src.tracker.github_tracker import GitHubReleaseTracker

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)


async def main():
    settings = get_settings()

    # 1. ä»é£ä¹¦Bitableè¯»å–æ‰€æœ‰GitHubå€™é€‰
    logger.info("ä»é£ä¹¦Bitableè¯»å–GitHubä»“åº“åˆ—è¡¨...")
    storage = StorageManager()
    existing_urls = await storage.get_existing_urls()

    github_urls = [url for url in existing_urls if "github.com" in url]
    logger.info(f"æ‰¾åˆ°{len(github_urls)}ä¸ªGitHubä»“åº“")

    if not github_urls:
        logger.info("æ— GitHubä»“åº“éœ€è¦è·Ÿè¸ª")
        return

    # 2. æ£€æŸ¥æ–°Release
    logger.info("æ£€æŸ¥GitHub Releaseæ›´æ–°...")
    github_token = settings.github.token if hasattr(settings, "github") else None
    tracker = GitHubReleaseTracker(github_token=github_token)
    new_releases = await tracker.check_updates(github_urls)

    if not new_releases:
        logger.info("æ— æ–°Release")
        return

    # 3. æ¨é€é£ä¹¦é€šçŸ¥
    logger.info(f"æ¨é€{len(new_releases)}ä¸ªæ–°Releaseé€šçŸ¥...")
    notifier = FeishuNotifier(settings=settings)

    for release in new_releases:
        message = (
            f"**GitHub Releaseæ›´æ–°**\n\n"
            f"ä»“åº“: {release.repo_url}\n"
            f"ç‰ˆæœ¬: {release.tag_name}\n"
            f"å‘å¸ƒæ—¶é—´: {release.published_at.strftime('%Y-%m-%d %H:%M')}\n\n"
            f"**æ›´æ–°è¯´æ˜**:\n{release.release_notes[:500]}\n\n"
            f"[æŸ¥çœ‹è¯¦æƒ…]({release.html_url})"
        )
        await notifier.send_text(message)

    logger.info("GitHub Releaseè·Ÿè¸ªä»»åŠ¡å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
```

**Step 4**: æ›´æ–° `src/tracker/__init__.py`

```python
from src.tracker.github_tracker import GitHubReleaseTracker

__all__ = ["GitHubReleaseTracker"]
```

**Step 5**: é…ç½®GitHub Actionså®šæ—¶ä»»åŠ¡

åœ¨ `.github/workflows/track_releases.yml` åˆ›å»ºï¼š
```yaml
name: Track GitHub Releases

on:
  schedule:
    - cron: '0 10 * * *'  # æ¯å¤©UTC 10:00 (åŒ—äº¬æ—¶é—´18:00)
  workflow_dispatch:      # æ”¯æŒæ‰‹åŠ¨è§¦å‘

jobs:
  track:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Track GitHub Releases
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
          FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}
          FEISHU_BITABLE_APP_TOKEN: ${{ secrets.FEISHU_BITABLE_APP_TOKEN }}
          FEISHU_BITABLE_TABLE_ID: ${{ secrets.FEISHU_BITABLE_TABLE_ID }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}  # GitHub Personal Access Token
        run: |
          python scripts/track_github_releases.py
```

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ‰‹åŠ¨æ·»åŠ ä¸€ä¸ªGitHub repoåˆ°é£ä¹¦è¡¨æ ¼ï¼‰

# 2. è¿è¡Œè·Ÿè¸ªè„šæœ¬
python scripts/track_github_releases.py

# é¢„æœŸè¾“å‡º:
# ä»é£ä¹¦Bitableè¯»å–GitHubä»“åº“åˆ—è¡¨...
# æ‰¾åˆ°Xä¸ªGitHubä»“åº“
# æ£€æŸ¥GitHub Releaseæ›´æ–°...
# å‘ç°æ–°Release: https://github.com/xxx/yyy - v1.2.0
# æ¨é€1ä¸ªæ–°Releaseé€šçŸ¥...
# GitHub Releaseè·Ÿè¸ªä»»åŠ¡å®Œæˆ

# 3. æ£€æŸ¥é£ä¹¦é€šçŸ¥
# é¢„æœŸ: æ”¶åˆ°åŒ…å«ç‰ˆæœ¬å·å’Œæ›´æ–°è¯´æ˜çš„é€šçŸ¥

# 4. å†æ¬¡è¿è¡Œï¼ˆåº”è¯¥æ— æ–°Releaseï¼‰
python scripts/track_github_releases.py

# é¢„æœŸè¾“å‡º:
# æ— æ–°Release
```

#### Commitæ ¼å¼

```bash
git add src/models.py src/tracker/ scripts/track_github_releases.py .github/workflows/track_releases.yml
git commit -m "feat(tracker): å®ç°GitHub Releaseç‰ˆæœ¬è·Ÿè¸ª

- åˆ›å»ºGitHubReleaseTrackerè·Ÿè¸ªå™¨
- ä»é£ä¹¦Bitableè¯»å–GitHubä»“åº“åˆ—è¡¨
- æŸ¥è¯¢GitHub APIè·å–æœ€æ–°Release
- SQLiteå­˜å‚¨å·²é€šçŸ¥çš„ç‰ˆæœ¬ï¼Œé¿å…é‡å¤
- é£ä¹¦æ¨é€æ–°Releaseé€šçŸ¥
- GitHub Actionså®šæ—¶ä»»åŠ¡ï¼ˆæ¯æ—¥18:00ï¼‰"
```

---

### Task 4.2: arXivç‰ˆæœ¬æ›´æ–°æé†’

**ä¼˜å…ˆçº§**: ğŸŸ¢ P2
**é¢„è®¡è€—æ—¶**: 1-2å°æ—¶
**éš¾åº¦**: â­â­ (ä¸­ç­‰)

#### éœ€æ±‚è¯´æ˜

arXivè®ºæ–‡å¯èƒ½æœ‰å¤šä¸ªç‰ˆæœ¬ï¼ˆv1, v2, v3...ï¼‰ï¼Œç›‘æ§å·²å…¥åº“è®ºæ–‡çš„ç‰ˆæœ¬æ›´æ–°ã€‚

**å®ç°ç­–ç•¥**:
1. ä»é£ä¹¦Bitableè¯»å–æ‰€æœ‰arXivç±»å‹çš„å€™é€‰
2. æå–arXiv IDï¼ˆå¦‚ `2311.04355`ï¼‰
3. æŸ¥è¯¢arXiv APIè·å–æœ€æ–°ç‰ˆæœ¬å·
4. å¯¹æ¯”æœ¬åœ°è®°å½•ï¼Œè¯†åˆ«ç‰ˆæœ¬æ›´æ–°
5. æ¨é€é£ä¹¦é€šçŸ¥

**æ•°æ®æ¨¡å‹**:
SQLiteæ–°å¢è¡¨ `arxiv_versions`:
```sql
CREATE TABLE arxiv_versions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    arxiv_id TEXT NOT NULL,            -- arXiv ID (e.g., 2311.04355)
    version TEXT NOT NULL,             -- ç‰ˆæœ¬å· (e.g., v3)
    updated_at TIMESTAMP NOT NULL,     -- æ›´æ–°æ—¶é—´
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(arxiv_id, version)
);
```

#### ä»£ç å®ç°æ¸…å•

**Step 1**: åˆ›å»ºç‰ˆæœ¬è·Ÿè¸ªå™¨ `src/tracker/arxiv_tracker.py`

```python
"""arXivè®ºæ–‡ç‰ˆæœ¬è·Ÿè¸ªå™¨"""
from __future__ import annotations

import logging
import re
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import List

import feedparser

logger = logging.getLogger(__name__)


class ArxivVersionTracker:
    """ç›‘æ§arXivè®ºæ–‡çš„ç‰ˆæœ¬æ›´æ–°"""

    def __init__(self, db_path: str = "fallback.db"):
        self.db_path = Path(db_path)
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS arxiv_versions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    arxiv_id TEXT NOT NULL,
                    version TEXT NOT NULL,
                    updated_at TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(arxiv_id, version)
                )
            """)
            conn.commit()
        logger.info("arXivç‰ˆæœ¬è·Ÿè¸ªæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    def _extract_arxiv_id(self, arxiv_url: str) -> str | None:
        """ä»arXiv URLæå–ID

        æ”¯æŒæ ¼å¼:
        - https://arxiv.org/abs/2311.04355
        - http://arxiv.org/abs/2311.04355v1
        - arxiv.org/abs/2311.04355

        Returns:
            arXiv ID (e.g., 2311.04355) æˆ– None
        """
        pattern = r"arxiv\.org/abs/(\d{4}\.\d{4,5})"
        if match := re.search(pattern, arxiv_url):
            return match.group(1)
        return None

    async def fetch_latest_version(self, arxiv_id: str) -> dict | None:
        """æŸ¥è¯¢arXivè®ºæ–‡çš„æœ€æ–°ç‰ˆæœ¬

        Args:
            arxiv_id: arXiv ID (e.g., 2311.04355)

        Returns:
            {'arxiv_id': str, 'version': str, 'updated': datetime, 'title': str} æˆ– None
        """
        query_url = f"http://export.arxiv.org/api/query?id_list={arxiv_id}"

        try:
            feed = feedparser.parse(query_url)

            if not feed.entries:
                logger.warning(f"æœªæ‰¾åˆ°arXivè®ºæ–‡: {arxiv_id}")
                return None

            entry = feed.entries[0]
            arxiv_url = entry.id  # æ ¼å¼: http://arxiv.org/abs/2311.04355v3

            # æå–ç‰ˆæœ¬å·
            version_match = re.search(r"v(\d+)$", arxiv_url)
            version = f"v{version_match.group(1)}" if version_match else "v1"

            return {
                "arxiv_id": arxiv_id,
                "version": version,
                "updated": datetime.fromisoformat(entry.updated.replace("Z", "+00:00")),
                "title": entry.title,
            }
        except Exception as exc:  # noqa: BLE001
            logger.error(f"æŸ¥è¯¢arXivç‰ˆæœ¬å¤±è´¥: {arxiv_id} - {exc}")
            return None

    def is_new_version(self, arxiv_id: str, version: str) -> bool:
        """æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦ä¸ºæ–°ç‰ˆæœ¬ï¼ˆæœªè®°å½•è¿‡ï¼‰"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT COUNT(*) FROM arxiv_versions WHERE arxiv_id = ? AND version = ?",
                (arxiv_id, version),
            )
            count = cursor.fetchone()[0]
            return count == 0

    def save_version(self, arxiv_id: str, version: str, updated_at: datetime):
        """ä¿å­˜ç‰ˆæœ¬åˆ°æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                INSERT OR IGNORE INTO arxiv_versions
                (arxiv_id, version, updated_at)
                VALUES (?, ?, ?)
                """,
                (arxiv_id, version, updated_at.isoformat()),
            )
            conn.commit()
        logger.info(f"ä¿å­˜arXivç‰ˆæœ¬: {arxiv_id} - {version}")

    async def check_updates(self, arxiv_urls: List[str]) -> List[dict]:
        """æ£€æŸ¥å¤šä¸ªè®ºæ–‡çš„ç‰ˆæœ¬æ›´æ–°

        Args:
            arxiv_urls: arXivè®ºæ–‡URLåˆ—è¡¨

        Returns:
            æ–°ç‰ˆæœ¬åˆ—è¡¨ [{'arxiv_id': str, 'version': str, 'updated': datetime, 'title': str}]
        """
        new_versions = []

        for url in arxiv_urls:
            arxiv_id = self._extract_arxiv_id(url)
            if not arxiv_id:
                logger.warning(f"æ— æ³•è§£æarXiv URL: {url}")
                continue

            logger.debug(f"æ£€æŸ¥arXivè®ºæ–‡: {arxiv_id}")
            version_info = await self.fetch_latest_version(arxiv_id)

            if version_info and self.is_new_version(version_info["arxiv_id"], version_info["version"]):
                logger.info(f"å‘ç°æ–°ç‰ˆæœ¬: {arxiv_id} - {version_info['version']}")
                self.save_version(arxiv_id, version_info["version"], version_info["updated"])
                new_versions.append(version_info)

        logger.info(f"arXivç‰ˆæœ¬æ£€æŸ¥å®Œæˆ: å…±{len(arxiv_urls)}ç¯‡è®ºæ–‡, å‘ç°{len(new_versions)}ä¸ªæ–°ç‰ˆæœ¬")
        return new_versions
```

**Step 2**: åˆ›å»ºè·Ÿè¸ªä»»åŠ¡è„šæœ¬ `scripts/track_arxiv_versions.py`

```python
"""arXivè®ºæ–‡ç‰ˆæœ¬è·Ÿè¸ªä»»åŠ¡

ä»é£ä¹¦Bitableè¯»å–æ‰€æœ‰arXivè®ºæ–‡ï¼Œæ£€æŸ¥ç‰ˆæœ¬æ›´æ–°å¹¶æ¨é€é€šçŸ¥

ç”¨æ³•:
    python scripts/track_arxiv_versions.py
"""
import asyncio
import logging
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import get_settings
from src.notifier import FeishuNotifier
from src.storage import StorageManager
from src.tracker.arxiv_tracker import ArxivVersionTracker

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)


async def main():
    settings = get_settings()

    # 1. ä»é£ä¹¦Bitableè¯»å–æ‰€æœ‰arXivå€™é€‰
    logger.info("ä»é£ä¹¦Bitableè¯»å–arXivè®ºæ–‡åˆ—è¡¨...")
    storage = StorageManager()
    existing_urls = await storage.get_existing_urls()

    arxiv_urls = [url for url in existing_urls if "arxiv.org" in url]
    logger.info(f"æ‰¾åˆ°{len(arxiv_urls)}ç¯‡arXivè®ºæ–‡")

    if not arxiv_urls:
        logger.info("æ— arXivè®ºæ–‡éœ€è¦è·Ÿè¸ª")
        return

    # 2. æ£€æŸ¥ç‰ˆæœ¬æ›´æ–°
    logger.info("æ£€æŸ¥arXivç‰ˆæœ¬æ›´æ–°...")
    tracker = ArxivVersionTracker()
    new_versions = await tracker.check_updates(arxiv_urls)

    if not new_versions:
        logger.info("æ— æ–°ç‰ˆæœ¬")
        return

    # 3. æ¨é€é£ä¹¦é€šçŸ¥
    logger.info(f"æ¨é€{len(new_versions)}ä¸ªç‰ˆæœ¬æ›´æ–°é€šçŸ¥...")
    notifier = FeishuNotifier(settings=settings)

    for version_info in new_versions:
        message = (
            f"**arXivè®ºæ–‡ç‰ˆæœ¬æ›´æ–°**\n\n"
            f"æ ‡é¢˜: {version_info['title']}\n"
            f"arXiv ID: {version_info['arxiv_id']}\n"
            f"æ–°ç‰ˆæœ¬: {version_info['version']}\n"
            f"æ›´æ–°æ—¶é—´: {version_info['updated'].strftime('%Y-%m-%d %H:%M')}\n\n"
            f"[æŸ¥çœ‹è®ºæ–‡](https://arxiv.org/abs/{version_info['arxiv_id']})"
        )
        await notifier.send_text(message)

    logger.info("arXivç‰ˆæœ¬è·Ÿè¸ªä»»åŠ¡å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
```

**Step 3**: æ›´æ–° `src/tracker/__init__.py`

```python
from src.tracker.arxiv_tracker import ArxivVersionTracker
from src.tracker.github_tracker import GitHubReleaseTracker

__all__ = ["ArxivVersionTracker", "GitHubReleaseTracker"]
```

**Step 4**: æ›´æ–°GitHub Actionså·¥ä½œæµï¼ˆåˆå¹¶åˆ°åŒä¸€ä¸ªæ–‡ä»¶ï¼‰

ä¿®æ”¹ `.github/workflows/track_releases.yml`:
```yaml
name: Track Updates

on:
  schedule:
    - cron: '0 10 * * *'  # æ¯å¤©UTC 10:00 (åŒ—äº¬æ—¶é—´18:00)
  workflow_dispatch:

jobs:
  track:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Track GitHub Releases
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
          FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}
          FEISHU_BITABLE_APP_TOKEN: ${{ secrets.FEISHU_BITABLE_APP_TOKEN }}
          FEISHU_BITABLE_TABLE_ID: ${{ secrets.FEISHU_BITABLE_TABLE_ID }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          python scripts/track_github_releases.py

      - name: Track arXiv Versions
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
          FEISHU_APP_SECRET: ${{ secrets.FEISHU_APP_SECRET }}
          FEISHU_BITABLE_APP_TOKEN: ${{ secrets.FEISHU_BITABLE_APP_TOKEN }}
          FEISHU_BITABLE_TABLE_ID: ${{ secrets.FEISHU_BITABLE_TABLE_ID }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: |
          python scripts/track_arxiv_versions.py
```

#### éªŒæ”¶æ ‡å‡†

```bash
# 1. è¿è¡Œè·Ÿè¸ªè„šæœ¬
python scripts/track_arxiv_versions.py

# é¢„æœŸè¾“å‡º:
# ä»é£ä¹¦Bitableè¯»å–arXivè®ºæ–‡åˆ—è¡¨...
# æ‰¾åˆ°Xç¯‡arXivè®ºæ–‡
# æ£€æŸ¥arXivç‰ˆæœ¬æ›´æ–°...
# å‘ç°æ–°ç‰ˆæœ¬: 2311.04355 - v2
# æ¨é€1ä¸ªç‰ˆæœ¬æ›´æ–°é€šçŸ¥...
# arXivç‰ˆæœ¬è·Ÿè¸ªä»»åŠ¡å®Œæˆ

# 2. æ£€æŸ¥é£ä¹¦é€šçŸ¥
# é¢„æœŸ: æ”¶åˆ°åŒ…å«ç‰ˆæœ¬å·å’Œæ›´æ–°æ—¶é—´çš„é€šçŸ¥

# 3. å†æ¬¡è¿è¡Œï¼ˆåº”è¯¥æ— æ–°ç‰ˆæœ¬ï¼‰
python scripts/track_arxiv_versions.py

# é¢„æœŸè¾“å‡º:
# æ— æ–°ç‰ˆæœ¬
```

#### Commitæ ¼å¼

```bash
git add src/tracker/arxiv_tracker.py scripts/track_arxiv_versions.py .github/workflows/track_releases.yml
git commit -m "feat(tracker): å®ç°arXivè®ºæ–‡ç‰ˆæœ¬è·Ÿè¸ª

- åˆ›å»ºArxivVersionTrackerè·Ÿè¸ªå™¨
- ä»é£ä¹¦Bitableè¯»å–arXivè®ºæ–‡åˆ—è¡¨
- æŸ¥è¯¢arXiv APIè·å–æœ€æ–°ç‰ˆæœ¬å·
- SQLiteå­˜å‚¨å·²é€šçŸ¥çš„ç‰ˆæœ¬ï¼Œé¿å…é‡å¤
- é£ä¹¦æ¨é€ç‰ˆæœ¬æ›´æ–°é€šçŸ¥
- GitHub Actionså®šæ—¶ä»»åŠ¡ï¼ˆä¸Releaseè·Ÿè¸ªåˆå¹¶ï¼‰"
```

---

### Task 4.3: Leaderboard SOTAå˜åŒ–è¿½è¸ªï¼ˆå¯é€‰ï¼‰

**ä¼˜å…ˆçº§**: ğŸŸ¢ P3ï¼ˆå¯é€‰ï¼‰
**é¢„è®¡è€—æ—¶**: 2-3å°æ—¶
**éš¾åº¦**: â­â­â­â­ (é«˜)

#### éœ€æ±‚è¯´æ˜

ç›‘æ§Benchmarkæ’è¡Œæ¦œï¼ˆå¦‚Papers with Code Leaderboardsï¼‰çš„SOTAå˜åŒ–ã€‚

**æŒ‘æˆ˜**:
- å„Benchmarkçš„Leaderboardæ ¼å¼ä¸ç»Ÿä¸€
- éœ€è¦å®šæœŸçˆ¬å–å¹¶å¯¹æ¯”åˆ†æ•°å˜åŒ–
- æ•°æ®æ¸…æ´—å’Œè§£æå¤æ‚åº¦é«˜

**å»ºè®®å®ç°æ–¹æ¡ˆ**:
1. ä»é£ä¹¦Bitableè¯»å–å€™é€‰çš„Leaderboard URL
2. ä½¿ç”¨BeautifulSoupçˆ¬å–æ’è¡Œæ¦œæ•°æ®
3. æå–Top 1çš„æ¨¡å‹åç§°å’Œåˆ†æ•°
4. å¯¹æ¯”ä¸Šæ¬¡è®°å½•ï¼Œè¯†åˆ«SOTAå˜åŒ–
5. æ¨é€é£ä¹¦é€šçŸ¥

**ç”±äºæ—¶é—´å’Œå¤æ‚åº¦é™åˆ¶ï¼Œå»ºè®®Phase 5å®ç°æˆ–å•ç‹¬ç«‹é¡¹**

---

## Phase 5: å¢å¼ºåŠŸèƒ½

**ç›®æ ‡**: æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢åŠ äº¤äº’åŠŸèƒ½
**é¢„è®¡è€—æ—¶**: 2-3å¤©
**ä¼˜å…ˆçº§**: ğŸŸ¢ ä½ï¼ˆé”¦ä¸Šæ·»èŠ±ï¼‰

---

### Task 5.1: é£ä¹¦å¡ç‰‡æ¶ˆæ¯æ›¿ä»£æ–‡æœ¬é€šçŸ¥

**ä¼˜å…ˆçº§**: ğŸŸ¢ P1
**é¢„è®¡è€—æ—¶**: 2-3å°æ—¶
**éš¾åº¦**: â­â­â­ (ä¸­é«˜)

#### éœ€æ±‚è¯´æ˜

å½“å‰é€šçŸ¥æ˜¯ç®€å•æ–‡æœ¬ï¼Œæ”¹ä¸ºé£ä¹¦å¡ç‰‡æ¶ˆæ¯ï¼ˆæ›´ç¾è§‚ã€æ”¯æŒæŒ‰é’®äº¤äº’ï¼‰ã€‚

**å¡ç‰‡æ¶ˆæ¯ç¤ºä¾‹**:
```json
{
  "msg_type": "interactive",
  "card": {
    "header": {
      "title": {
        "content": "ğŸ”¥ å‘ç°é«˜è´¨é‡Benchmarkå€™é€‰",
        "tag": "plain_text"
      },
      "template": "blue"
    },
    "elements": [
      {
        "tag": "div",
        "text": {
          "content": "**æ ‡é¢˜**: BenchX - Code Generation Benchmark\n**æ¥æº**: arXiv\n**æ€»åˆ†**: 8.5/10",
          "tag": "lark_md"
        }
      },
      {
        "tag": "action",
        "actions": [
          {
            "tag": "button",
            "text": {
              "content": "æŸ¥çœ‹è¯¦æƒ…",
              "tag": "plain_text"
            },
            "url": "https://arxiv.org/abs/xxx",
            "type": "default"
          },
          {
            "tag": "button",
            "text": {
              "content": "âœ… åŠ å…¥å€™é€‰æ± ",
              "tag": "plain_text"
            },
            "value": {
              "action": "approve",
              "candidate_id": "xxx"
            },
            "type": "primary"
          }
        ]
      }
    ]
  }
}
```

#### ä»£ç ä¿®æ”¹æ¸…å•

**Step 1**: ä¿®æ”¹ `src/notifier/feishu_notifier.py`

å¢åŠ å¡ç‰‡æ¶ˆæ¯æ–¹æ³•ï¼š
```python
async def send_card(self, title: str, candidate: ScoredCandidate):
    """å‘é€é£ä¹¦å¡ç‰‡æ¶ˆæ¯

    Args:
        title: å¡ç‰‡æ ‡é¢˜
        candidate: è¯„åˆ†åçš„å€™é€‰å¯¹è±¡
    """
    card = {
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {"content": title, "tag": "plain_text"},
                "template": "blue" if candidate.priority == "high" else "green",
            },
            "elements": [
                {
                    "tag": "div",
                    "text": {
                        "content": (
                            f"**æ ‡é¢˜**: {candidate.title}\n"
                            f"**æ¥æº**: {candidate.source}\n"
                            f"**æ€»åˆ†**: {candidate.total_score:.2f}/10\n"
                            f"**ä¼˜å…ˆçº§**: {candidate.priority}"
                        ),
                        "tag": "lark_md",
                    },
                },
                {
                    "tag": "div",
                    "text": {
                        "content": f"**è¯„åˆ†ä¾æ®**:\n{candidate.reasoning[:300]}...",
                        "tag": "lark_md",
                    },
                },
                {
                    "tag": "action",
                    "actions": [
                        {
                            "tag": "button",
                            "text": {"content": "æŸ¥çœ‹è¯¦æƒ…", "tag": "plain_text"},
                            "url": candidate.url,
                            "type": "default",
                        }
                    ],
                },
            ],
        },
    }

    await self._send_webhook(card)
```

ä¿®æ”¹ `notify` æ–¹æ³•ï¼š
```python
async def notify(self, candidates: List[ScoredCandidate]) -> None:
    """æ¨é€å€™é€‰é€šçŸ¥ï¼ˆå¡ç‰‡æ¶ˆæ¯ï¼‰"""
    if not candidates:
        return

    high_priority = [c for c in candidates if c.priority == "high"]

    # æ¨é€é«˜ä¼˜å…ˆçº§å€™é€‰ï¼ˆå•ç‹¬å¡ç‰‡ï¼‰
    for candidate in high_priority[:3]:  # é™åˆ¶æœ€å¤š3ä¸ª
        await self.send_card("ğŸ”¥ å‘ç°é«˜è´¨é‡Benchmarkå€™é€‰", candidate)
        await asyncio.sleep(0.5)  # é˜²æ­¢é™æµ

    # æ¨é€æ±‡æ€»é€šçŸ¥
    summary = (
        f"æœ¬æ¬¡é‡‡é›†å®Œæˆ:\n"
        f"- é«˜ä¼˜å…ˆçº§: {len(high_priority)}æ¡\n"
        f"- ä¸­ä¼˜å…ˆçº§: {len([c for c in candidates if c.priority == 'medium'])}æ¡\n"
        f"- å¹³å‡åˆ†: {sum(c.total_score for c in candidates) / len(candidates):.2f}/10"
    )
    await self.send_text(summary)
```

#### éªŒæ”¶æ ‡å‡†

```bash
# è¿è¡Œpipeline
python src/main.py

# é¢„æœŸ: é£ä¹¦æ”¶åˆ°ç¾è§‚çš„å¡ç‰‡æ¶ˆæ¯ï¼ˆå¸¦æ ‡é¢˜ã€è¯„åˆ†ã€æŒ‰é’®ï¼‰
```

#### Commitæ ¼å¼

```bash
git add src/notifier/feishu_notifier.py
git commit -m "feat(notifier): é£ä¹¦é€šçŸ¥å‡çº§ä¸ºå¡ç‰‡æ¶ˆæ¯

- æ›¿æ¢ç®€å•æ–‡æœ¬é€šçŸ¥ä¸ºäº¤äº’å¼å¡ç‰‡
- å¡ç‰‡æ˜¾ç¤º: æ ‡é¢˜/æ¥æº/æ€»åˆ†/ä¼˜å…ˆçº§/è¯„åˆ†ä¾æ®
- å¢åŠ "æŸ¥çœ‹è¯¦æƒ…"æŒ‰é’®è·³è½¬åŸæ–‡
- ä¼˜å…ˆçº§é«˜çš„å€™é€‰å•ç‹¬æ¨é€å¡ç‰‡
- æå‡é€šçŸ¥å¯è¯»æ€§å’Œäº¤äº’ä½“éªŒ"
```

---

### Phase 5 å…¶ä»–å¯é€‰ä»»åŠ¡

**Task 5.2**: ä¸€é”®æ·»åŠ æŒ‰é’® + Flaskå›è°ƒæœåŠ¡ï¼ˆéœ€è¦éƒ¨ç½²WebæœåŠ¡ï¼Œå¤æ‚åº¦é«˜ï¼‰
**Task 5.3**: å€™é€‰æ± ç®¡ç†åå°ï¼ˆWebç•Œé¢ï¼Œå¯è§†åŒ–ç®¡ç†ï¼Œå»ºè®®å•ç‹¬ç«‹é¡¹ï¼‰
**Task 5.4**: è¯„åˆ†æ¨¡å‹å¾®è°ƒï¼ˆåŸºäºäººå·¥åé¦ˆï¼Œé•¿æœŸè¿­ä»£ä»»åŠ¡ï¼‰

---

## æµ‹è¯•ä¸éªŒæ”¶æµç¨‹

### å•å…ƒæµ‹è¯•è§„èŒƒ

**æµ‹è¯•æ–‡ä»¶ç»„ç»‡**:
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_collectors.py      # é‡‡é›†å™¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_prefilter.py        # é¢„ç­›é€‰æµ‹è¯•
â”‚   â”œâ”€â”€ test_scorer.py           # è¯„åˆ†å™¨æµ‹è¯•
â”‚   â”œâ”€â”€ test_storage.py          # å­˜å‚¨å±‚æµ‹è¯•
â”‚   â”œâ”€â”€ test_notifier.py         # é€šçŸ¥å™¨æµ‹è¯•
â”‚   â””â”€â”€ test_tracker.py          # è·Ÿè¸ªå™¨æµ‹è¯•ï¼ˆæ–°å¢ï¼‰
â””â”€â”€ integration/
    â””â”€â”€ test_pipeline.py         # å®Œæ•´æµç¨‹æµ‹è¯•
```

**æµ‹è¯•å‘½ä»¤**:
```bash
# è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•
pytest tests/unit/ -v

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
pytest tests/unit/test_tracker.py -v

# è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆéœ€è¦çœŸå®APIé…ç½®ï¼‰
pytest tests/integration/ -v

# æµ‹è¯•è¦†ç›–ç‡
pytest --cov=src --cov-report=html
```

### é›†æˆæµ‹è¯•æµç¨‹

**å®Œæ•´Pipelineæµ‹è¯•**:
```bash
# 1. æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate
export PYTHONPATH=.

# 2. æ¸…ç©ºRedisç¼“å­˜
redis-cli FLUSHALL

# 3. æ¸…ç©ºé£ä¹¦è¡¨æ ¼ï¼ˆå¯é€‰ï¼‰
python scripts/clear_feishu_table.py

# 4. è¿è¡Œå®Œæ•´pipeline
python src/main.py 2>&1 | tee logs/integration_test_$(date +%Y%m%d_%H%M%S).log

# 5. åˆ†ææ—¥å¿—
python scripts/analyze_logs.py logs/integration_test_*.log

# 6. éªŒè¯å…³é”®æŒ‡æ ‡
grep -E "(é‡‡é›†|å»é‡|é¢„ç­›é€‰|è¯„åˆ†|å­˜å‚¨|é€šçŸ¥)" logs/integration_test_*.log
```

**é¢„æœŸç»“æœ**:
- âœ… æ•°æ®é‡‡é›†æˆåŠŸç‡ > 95%
- âœ… å»é‡åŠŸèƒ½æ­£å¸¸ï¼ˆè¿‡æ»¤å·²æ¨é€URLï¼‰
- âœ… GitHubé¢„ç­›é€‰é€šè¿‡ç‡ 10-30%ï¼ˆä¸å†100%ï¼‰
- âœ… LLMè¯„åˆ†æˆåŠŸï¼Œå¹³å‡åˆ†6-8/10
- âœ… é£ä¹¦å­˜å‚¨æˆåŠŸï¼Œæ— é™çº§åˆ°SQLite
- âœ… é£ä¹¦é€šçŸ¥æˆåŠŸæ¨é€
- âœ… æ‰§è¡Œæ—¶é—´ < 20åˆ†é’Ÿ

### æ‰‹åŠ¨éªŒæ”¶æ£€æŸ¥æ¸…å•

**Phase 3éªŒæ”¶**:
- [ ] è¿è¡Œpipelineæ— PwCé”™è¯¯æ—¥å¿—
- [ ] GitHubé‡‡é›†æ•°é‡åˆç†ï¼ˆ5-15æ¡ï¼Œ30å¤©çª—å£ï¼‰
- [ ] GitHubé¢„ç­›é€‰é€šè¿‡1-5æ¡ï¼ˆ10-30%é€šè¿‡ç‡ï¼‰
- [ ] HuggingFaceæ—¶é—´è¿‡æ»¤ç”Ÿæ•ˆï¼ˆæ—¥å¿—æ˜¾ç¤ºè¿‡æ»¤æ•°é‡ï¼‰
- [ ] æ—¥å¿—åˆ†æå·¥å…·æ­£å¸¸è¾“å‡ºæŠ¥å‘Š
- [ ] è¯„åˆ†æƒé‡è°ƒæ•´ç”Ÿæ•ˆï¼ˆMGXç›¸å…³å€™é€‰åˆ†æ•°æå‡ï¼‰

**Phase 4éªŒæ”¶**:
- [ ] GitHub Releaseè·Ÿè¸ªæ­£å¸¸ï¼ˆæ£€æµ‹åˆ°æ–°ç‰ˆæœ¬ï¼‰
- [ ] arXivç‰ˆæœ¬è·Ÿè¸ªæ­£å¸¸ï¼ˆæ£€æµ‹åˆ°v2/v3æ›´æ–°ï¼‰
- [ ] é£ä¹¦æ”¶åˆ°ç‰ˆæœ¬æ›´æ–°é€šçŸ¥
- [ ] SQLiteæ­£ç¡®å­˜å‚¨ç‰ˆæœ¬è®°å½•
- [ ] GitHub Actionså®šæ—¶ä»»åŠ¡è¿è¡ŒæˆåŠŸ

**Phase 5éªŒæ”¶**:
- [ ] é£ä¹¦æ”¶åˆ°å¡ç‰‡æ¶ˆæ¯ï¼ˆéæ–‡æœ¬ï¼‰
- [ ] å¡ç‰‡æ˜¾ç¤ºå®Œæ•´ä¿¡æ¯ï¼ˆæ ‡é¢˜/è¯„åˆ†/æŒ‰é’®ï¼‰
- [ ] ç‚¹å‡»æŒ‰é’®è·³è½¬æ­£ç¡®

---

## ä»£ç è§„èŒƒä¸çº¦æŸ

### Pythonä»£ç è§„èŒƒï¼ˆå¼ºåˆ¶æ‰§è¡Œï¼‰

1. **PEP8åˆè§„**:
   ```bash
   # è‡ªåŠ¨æ ¼å¼åŒ–
   black src/ tests/ scripts/

   # ä»£ç æ£€æŸ¥
   ruff check src/ tests/ scripts/
   ```

2. **ç±»å‹æ³¨è§£**:
   ```python
   # å¥½çš„ä¾‹å­
   def fetch_latest_release(self, repo_url: str) -> GitHubRelease | None:
       ...

   # åçš„ä¾‹å­
   def fetch_latest_release(self, repo_url):
       ...
   ```

3. **ä¸­æ–‡æ³¨é‡Šï¼ˆå…³é”®é€»è¾‘å¿…é¡»ï¼‰**:
   ```python
   # å¥½çš„ä¾‹å­
   # è®¡ç®—æ—¶é—´çª—å£ï¼ˆä»constantsä¸­è¯»å–ï¼‰
   lookback_date = datetime.now(timezone.utc) - timedelta(days=constants.GITHUB_LOOKBACK_DAYS)

   # åçš„ä¾‹å­
   lookback_date = datetime.now(timezone.utc) - timedelta(days=constants.GITHUB_LOOKBACK_DAYS)  # æ— æ³¨é‡Š
   ```

4. **å¸¸é‡å®šä¹‰ï¼ˆç¦æ­¢é­”æ³•æ•°å­—ï¼‰**:
   ```python
   # å¥½çš„ä¾‹å­
   PREFILTER_MIN_GITHUB_STARS: Final[int] = 10
   if stars < constants.PREFILTER_MIN_GITHUB_STARS:
       ...

   # åçš„ä¾‹å­
   if stars < 10:  # é­”æ³•æ•°å­—
       ...
   ```

5. **å‡½æ•°åµŒå¥—å±‚çº§ï¼ˆæœ€å¤š3å±‚ï¼‰**:
   ```python
   # å¥½çš„ä¾‹å­ï¼ˆä½¿ç”¨early returnï¼‰
   def validate(self, candidate):
       if not candidate.url:
           return False
       if not self._is_valid_source(candidate.source):
           return False
       return True

   # åçš„ä¾‹å­ï¼ˆåµŒå¥—è¿‡æ·±ï¼‰
   def validate(self, candidate):
       if candidate.url:
           if self._is_valid_source(candidate.source):
               if self._check_quality(candidate):
                   return True
       return False
   ```

### Git Commitè§„èŒƒ

**æ ¼å¼**:
```
<type>(<scope>): <subject>

<body>

<footer>
```

**ç±»å‹ï¼ˆtypeï¼‰**:
- `feat`: æ–°åŠŸèƒ½
- `fix`: Bugä¿®å¤
- `refactor`: é‡æ„ï¼ˆä¸æ”¹å˜åŠŸèƒ½ï¼‰
- `perf`: æ€§èƒ½ä¼˜åŒ–
- `docs`: æ–‡æ¡£æ›´æ–°
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»º/å·¥å…·é“¾æ›´æ–°

**èŒƒå›´ï¼ˆscopeï¼‰**:
- `collectors`: æ•°æ®é‡‡é›†å™¨
- `prefilter`: é¢„ç­›é€‰å¼•æ“
- `scorer`: è¯„åˆ†å¼•æ“
- `storage`: å­˜å‚¨å±‚
- `notifier`: é€šçŸ¥å¼•æ“
- `tracker`: ç‰ˆæœ¬è·Ÿè¸ªå™¨
- `scripts`: è„šæœ¬å·¥å…·

**ç¤ºä¾‹**:
```bash
feat(tracker): å®ç°GitHub Releaseç‰ˆæœ¬è·Ÿè¸ª

- åˆ›å»ºGitHubReleaseTrackerè·Ÿè¸ªå™¨
- ä»é£ä¹¦Bitableè¯»å–GitHubä»“åº“åˆ—è¡¨
- æŸ¥è¯¢GitHub APIè·å–æœ€æ–°Release
- SQLiteå­˜å‚¨å·²é€šçŸ¥çš„ç‰ˆæœ¬ï¼Œé¿å…é‡å¤
- é£ä¹¦æ¨é€æ–°Releaseé€šçŸ¥
- GitHub Actionså®šæ—¶ä»»åŠ¡ï¼ˆæ¯æ—¥18:00ï¼‰

Closes #42
```

### å¼‚å¸¸å¤„ç†è§„èŒƒ

```python
# å¥½çš„ä¾‹å­ï¼ˆå…·ä½“å¼‚å¸¸+æ—¥å¿—ï¼‰
try:
    resp = await client.get(api_url)
    resp.raise_for_status()
except httpx.HTTPStatusError as exc:
    if exc.response.status_code == 404:
        logger.debug(f"ä»“åº“æ— Release: {repo_url}")
    else:
        logger.warning(f"æŸ¥è¯¢å¤±è´¥: {repo_url} - {exc}")
    return None
except httpx.TimeoutException:
    logger.error(f"è¯·æ±‚è¶…æ—¶: {repo_url}")
    return None

# åçš„ä¾‹å­ï¼ˆé€šç”¨å¼‚å¸¸+æ— æ—¥å¿—ï¼‰
try:
    resp = await client.get(api_url)
    resp.raise_for_status()
except Exception:
    return None
```

---

## å¼€å‘æ‰§è¡Œé¡ºåºå»ºè®®

**Codexï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹é¡ºåºæ‰§è¡Œå¼€å‘ä»»åŠ¡**:

### Week 1: Phase 3æ ¸å¿ƒä¼˜åŒ–

**Day 1**:
- [ ] Task 3.1: ç§»é™¤PwCé‡‡é›†å™¨ï¼ˆ30åˆ†é’Ÿï¼‰
- [ ] Task 3.2: ä¼˜åŒ–GitHubé¢„ç­›é€‰è§„åˆ™ï¼ˆ2å°æ—¶ï¼‰
- [ ] æµ‹è¯•éªŒæ”¶ï¼Œæäº¤ä»£ç 

**Day 2**:
- [ ] Task 3.3: å®ç°æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆ2å°æ—¶ï¼‰
- [ ] Task 3.4: åˆ›å»ºæ—¥å¿—åˆ†æå·¥å…·ï¼ˆ1å°æ—¶ï¼‰
- [ ] æµ‹è¯•éªŒæ”¶ï¼Œæäº¤ä»£ç 

**Day 3**:
- [ ] Task 3.5: è°ƒæ•´è¯„åˆ†æƒé‡ï¼ˆ30åˆ†é’Ÿï¼Œå¯é€‰ï¼‰
- [ ] Phase 3å®Œæ•´é›†æˆæµ‹è¯•
- [ ] æäº¤Phase 3æ€»ç»“æŠ¥å‘Šç»™Claude CodeéªŒæ”¶

### Week 2: Phase 4ç‰ˆæœ¬è·Ÿè¸ª

**Day 4**:
- [ ] Task 4.1: GitHub Releaseç›‘æ§ï¼ˆ3å°æ—¶ï¼‰
- [ ] æµ‹è¯•éªŒæ”¶ï¼Œæäº¤ä»£ç 

**Day 5**:
- [ ] Task 4.2: arXivç‰ˆæœ¬æ›´æ–°æé†’ï¼ˆ2å°æ—¶ï¼‰
- [ ] Phase 4é›†æˆæµ‹è¯•
- [ ] æäº¤Phase 4æ€»ç»“æŠ¥å‘Šç»™Claude CodeéªŒæ”¶

### Week 3: Phase 5å¢å¼ºåŠŸèƒ½ï¼ˆå¯é€‰ï¼‰

**Day 6**:
- [ ] Task 5.1: é£ä¹¦å¡ç‰‡æ¶ˆæ¯ï¼ˆ3å°æ—¶ï¼‰
- [ ] Phase 5æµ‹è¯•éªŒæ”¶

**Day 7**:
- [ ] å…¨æµç¨‹é›†æˆæµ‹è¯•
- [ ] æ–‡æ¡£æ›´æ–°ï¼ˆREADME, CLAUDE.mdï¼‰
- [ ] æœ€ç»ˆéªŒæ”¶æŠ¥å‘Š

---

## å®Œæˆæ ‡å‡†ä¸éªŒæ”¶

### Phase 3éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½å®Œæ•´æ€§**:
- [x] PwCé‡‡é›†å™¨å·²ç§»é™¤ï¼Œæ— é”™è¯¯æ—¥å¿—
- [x] GitHubé¢„ç­›é€‰é€šè¿‡ç‡10-30%
- [x] æ—¶é—´çª—å£è¿‡æ»¤ç”Ÿæ•ˆ
- [x] æ—¥å¿—åˆ†æå·¥å…·å¯ç”¨
- [x] è¯„åˆ†æƒé‡å·²è°ƒæ•´ï¼ˆå¯é€‰ï¼‰

**ä»£ç è´¨é‡**:
- [x] æ‰€æœ‰ä¿®æ”¹ç¬¦åˆPEP8è§„èŒƒ
- [x] å…³é”®é€»è¾‘æœ‰ä¸­æ–‡æ³¨é‡Š
- [x] æ— ç¡¬ç¼–ç é­”æ³•æ•°å­—
- [x] å¼‚å¸¸å¤„ç†å®Œå–„

**æµ‹è¯•è¦†ç›–**:
- [x] å•å…ƒæµ‹è¯•é€šè¿‡
- [x] é›†æˆæµ‹è¯•é€šè¿‡
- [x] æ‰‹åŠ¨éªŒæ”¶å®Œæˆ

### Phase 4éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½å®Œæ•´æ€§**:
- [x] GitHub Releaseç›‘æ§æ­£å¸¸
- [x] arXivç‰ˆæœ¬è·Ÿè¸ªæ­£å¸¸
- [x] é£ä¹¦é€šçŸ¥æ¨é€æˆåŠŸ
- [x] SQLiteå­˜å‚¨ç‰ˆæœ¬è®°å½•
- [x] GitHub Actionså®šæ—¶ä»»åŠ¡è¿è¡Œ

**ä»£ç è´¨é‡**:
- [x] ç¬¦åˆä»£ç è§„èŒƒ
- [x] å¼‚å¸¸å¤„ç†å¥å£®
- [x] æ—¥å¿—å®Œå–„æ¸…æ™°

**æµ‹è¯•è¦†ç›–**:
- [x] å•å…ƒæµ‹è¯•é€šè¿‡
- [x] é›†æˆæµ‹è¯•é€šè¿‡
- [x] æ‰‹åŠ¨éªŒæ”¶å®Œæˆ

### Phase 5éªŒæ”¶æ ‡å‡†

**åŠŸèƒ½å®Œæ•´æ€§**:
- [x] é£ä¹¦å¡ç‰‡æ¶ˆæ¯æ˜¾ç¤ºæ­£å¸¸
- [x] æŒ‰é’®è·³è½¬åŠŸèƒ½æ­£å¸¸

**ä»£ç è´¨é‡**:
- [x] ç¬¦åˆä»£ç è§„èŒƒ

**æµ‹è¯•è¦†ç›–**:
- [x] æ‰‹åŠ¨éªŒæ”¶å®Œæˆ

---

## å¸¸è§é—®é¢˜FAQ

**Q1: å¦‚ä½•å¤„ç†APIé™æµ?**
A: ä½¿ç”¨æŒ‡æ•°é€€é¿é‡è¯• + é™ä½å¹¶å‘åº¦ + å¢åŠ å»¶è¿Ÿã€‚ç¤ºä¾‹:
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=10))
async def fetch_with_retry(url):
    ...
```

**Q2: é£ä¹¦APIå¤±è´¥å¦‚ä½•é™çº§?**
A: è‡ªåŠ¨é™çº§åˆ°SQLiteå¤‡ä»½ï¼Œå‚è€ƒ`StorageManager`å®ç°ã€‚

**Q3: å¦‚ä½•è°ƒè¯•LLMè¯„åˆ†é—®é¢˜?**
A:
1. æ£€æŸ¥`logs/benchscope.log`ä¸­çš„"LLMåŸå§‹å“åº”"
2. ç¡®è®¤JSONæ ¼å¼æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥æ˜¯å¦è¢«markdownä»£ç å—åŒ…è£¹

**Q4: GitHub Actionsæ— æ³•è®¿é—®secretsæ€ä¹ˆåŠ?**
A: åœ¨GitHubä»“åº“Settings â†’ Secrets and variables â†’ Actionsä¸­æ·»åŠ ã€‚

**Q5: å¦‚ä½•æ¸…ç©ºæµ‹è¯•æ•°æ®é‡æ–°å¼€å§‹?**
A:
```bash
# æ¸…ç©ºé£ä¹¦è¡¨æ ¼
python scripts/clear_feishu_table.py

# æ¸…ç©ºRedisç¼“å­˜
redis-cli FLUSHALL

# åˆ é™¤SQLiteæ•°æ®åº“
rm fallback.db
```

---

## è”ç³»ä¸æ”¯æŒ

**å¼€å‘è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜**:
1. æ£€æŸ¥æœ¬æ–‡æ¡£FAQéƒ¨åˆ†
2. æŸ¥çœ‹`docs/test-report.md`å†å²æµ‹è¯•ç»“æœ
3. é€šçŸ¥Claude CodeéªŒæ”¶æ—¶è¯´æ˜å…·ä½“é—®é¢˜

**æäº¤ä»£ç å‰æ£€æŸ¥**:
- [ ] ä»£ç ç¬¦åˆPEP8è§„èŒƒï¼ˆè¿è¡Œ`black`å’Œ`ruff`ï¼‰
- [ ] å…³é”®é€»è¾‘æœ‰ä¸­æ–‡æ³¨é‡Š
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] æ‰‹åŠ¨æµ‹è¯•é€šè¿‡
- [ ] Commit messageç¬¦åˆè§„èŒƒ
- [ ] å·²é€šçŸ¥Claude CodeéªŒæ”¶

---

**ç¥å¼€å‘é¡ºåˆ©ï¼è¯·ä¸¥æ ¼æŒ‰ç…§æœ¬æ–‡æ¡£æ‰§è¡Œï¼Œæ¯å®Œæˆä¸€ä¸ªTaskç«‹å³æäº¤å¹¶é€šçŸ¥Claude CodeéªŒæ”¶ã€‚** ğŸš€
